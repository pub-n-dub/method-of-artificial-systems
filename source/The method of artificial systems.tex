%% LyX 2.3.7 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[a4paper,english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{float}
\usepackage{textcomp}
\usepackage{amstext}
\usepackage{graphicx}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\special{papersize=\the\paperwidth,\the\paperheight}


\makeatother

\usepackage{babel}
\begin{document}
\title{The Method of Artificial Systems}
\maketitle
\begin{abstract}
This work will focus primarily on two main concepts: context awareness
and choice in artificial systems limited by a fluid yet rigorous epistemology.
I argue this will allow the strongest adaptation mechanism in an artificial
entity. I will present this argument by giving a background of the
problem, illustrating different points of view, and reveal a method
which can generate tangible experiments to understand the scope of
the problems currently in artificial life and machine consciousness. 

\tableofcontents{}
\end{abstract}
\listoffigures


\section{Introduction}

This work will protract a differing and unique analysis of and propose
a final solution to Artificial Intelligence / Artificial Life (AI
/ AL) by taking the position that machines should not be designed
to force-fit them into unsuitable models, but instead should be designed
as life-forms in their own right and subject to the same rules as
other living systems. I argue that a well-defined intent and engineering
workspace will inspire more complex machines with greater ranges of
adapted behaviors.

Foundations of machine life are imperative to establish in order to
facilitate evolution from present-day rudimentary forms into those
more advanced. Although numerous forms exist today, a proper architecture
of similitude, laws, modes, and orchestration needs to be authored
to establish baselines for generational development of the artificial
life form.

I propose to accomplish this by establishing three goals to be pursued
here:

1. It is the goal of this thesis to establish a methodological and
experimental foundation to understand and construct autonomous synthetic
creatures of varying purpose. Directed by the application environment,
machine types form an active role of technological development and
should be categorized if possible,

2. It is the goal of research contained here to understand artificial
life (and perhaps shed some light on what is life in a more general
sense) by designing and constructing mimicking forms,

3. It is the goal of experiments proposed here to actualize motifs
of behavior, to establish a paradigmic set of discretionary limits,
necessitated by a physical characteristic.

This document will set out to introduce the proposals that will be
in the subsequent thesis, set out a path of how the proposals will
be solved, the research involved, and the benefits to humanity and
expanse of knowledge to the body of science. Much of this thesis,
however, will not be derived to the last detail as such works are
left for the pursuit of the dissertation; however, I would like to
communicate to the reader my intentions with my topic and my opinions
regarding analytical results I have gleaned from research into historical
works and independent conclusions based on such listed in the ``References''
section of this document.

Over the course of my studies in my academic and professional career,
I have always been fascinated by robots and have a particular affinity
for machines in general. Most of my career has been involved in some
aspect of machines from maintenance to engineering to software development
and through these experiences, I have a unique insight into the problems
of AI and believe the problem has been nearly solved. With the engineering
of humanoid robots such as those being manufactured on a limited scale
in Japan and South Korea, I see the last step of development is adaptive
software in a common-use compiler for mass consumption and a unified
programmatic, functional, and state development environment. It is
my sincere opinion that this problem will be solved near-complete
by late 2012. My only hope in this time is that my contributions are
recognized.

\subsection{Terms}

This thesis will deal with loosely-defined concepts nested in objective
terms such as `robot', `machine', `autonomous', `synthetic creature'
and the like to describe heretofore abstractly realized phenomenon
that which comes so easily for us to recognize when we see it. It
is one of the goals of this document to establish a set of terms suitable
and narrowly defined to carry specific and targeted meaning of the
abstract concepts that will be introduced and explored herein. The
terms used widely throughout this thesis are: 

Feature: the prominent part or characteristic embedded in both physical
and abstract components.

Entity: a dynamic object that possesses behavior forming an commonly-identifiable
form.

Robot: I will use this term interchangeably with `machine', `autonomous
entity', and `synthetic creature' meaning a composite artificial life
form who may or may not bear resemblance to a humanoid form. I do
not use it in its original context or in its exact translation.

Controller: an entity that insists on particular machine states based
on an external criteria or paradigm.

Orchestration: Cooperation between disparate physical or abstract
elements resulting in finely-grained coordination.

Autonomy: A system defined by its own behavior derived from experience.

I employ the terms `life' and `living' loosely throughout this thesis.
I will use the terms to mean `any system constructed or natural that
interacts directly with a human observer generating interest'. Granted
the definition is limited and perhaps flawed, it is for the conclusion
of the research during my dissertation that this will be rectified.
For now, I don't want to be mired in the metaphysical aspects while
just beginning the work, hence the abbreviation here.

\subsection{The Reluctance of AI}

Artificial intelligence requires three basic mathematical components,
or ingredients, to make it what it is. The formal science requires
a level of mathematical formulisation in computation, logic, and probability;
it wasn't until the appearance of George Boole (1815 - 1864) and Gottlob
Frege (1848 - 1925) that knowledge representation was defined. Alfred
Tarski (1902 - 1983) introduced a theory of reference showing how
logical objects could be related to their real-world counterparts.
Turing, following Godel's incompleteness theorem, demonstrated what
kinds of functions could be computed, expressed as the Church-Turing
thesis. However, this introduced a series of intractable problems
that would be left until the appearance of complexity theory in the
1970s to be shown how to compute proper solutions from problem instances.

The history of artificial intelligence stretches back to the first
doctrines of logic by Plato and the development of mathematics by
luminaries such as Archimedes which disappeared until rediscovery
in the 18th Century. Part of this thesis will reexamine some of the
more intractable problems in AI such as knowledge representation and
choice-motivated decision-making by examining them in a geometric
light. However, this has not been developed far at the time of the
writing of this document and will be included in future revisions.
Nevertheless, a comprehensive look of assets and alternatives is due
the field wherein new theoretical, abstract, and experimental paradigms
can be generated.

I will take the time to mention here that a series of confessions
have bled into the media of late. One of the more notable was one
by Rodney Brooks that caught my attention. However, the reluctance
of AI can be traced back to the Lighthill Report which can be summarized
as a critical review of the power of AI professed by its earliest
proponents in the mid 20th Century. The result was that many programs
were closed in the University system and others were renamed to keep
them going. However, the shadow of failure seems to still permeate
to this day. If the recent confessions are an indicator of the validity
of the Lighthill Report then Brooks' confession of failure ``in solving
the AI problem'',\cite{key-2} might indeed point to a fundamental
flaw in the field that should be identified before any further work
is conducted--hence why I addresses this issue in the first section.

I don't think this is a failure of the individual research in question,
but is indicative of a more endemic problem buried deep in the field,
something between those properties discussed at the earliest conferences
in the late 1950s--hosted by von Neumann and expounded by Turing--and
how they were manifest in technology decades later. Norbert Wiener
comes to mind who prophesied many types of intelligent machines and
started a conference track attended by the future founders of cybernetics:
W. Ross Ashby, Grey Walter, and Warren McCulloch. However, despite
attention given to this field, many works did not persist beyond their
creators. There was, of course, some dissemination of concepts such
as homeostasis by Ashby and the circuits of Walter's tortoises--specifications
of which were reexamined in 2003\cite{key-3}--however, it could
not be discovered if their works made their way into commercial projects.
This does not imply that the founders of the field necessarily failed;
there were some interesting and successful developments in robots
for space exploration beginning with the Luna Project by the Soviet
Union that cumulated in the Mars exploratory robots that have shown
how robust such a system can be made not to mention adaptive to deal
with the conditions on a hostile planet so far from its source. So
there have been some shining examples and some catastrophic failures--was
Big Blue really intelligent? I argue that it wasn't. Some applications
are simply misguided and I point to the lack of continuity in the
field; although Wiener's machines were behemoths, Stanford Beer's
economic and business derivations were sublime. Somewhere between
creating theory and the delicate operation of putting the theory into
operation lies a serious rub that can be solved in a myriad of ways.
There must be a way to derive a language framework wherein to eliminate
trivialities of semantics to unite a field as disparate and wide-reaching
as cybernetics.

So what kind of machines will be discussed here? I will focus on a
single realization, robotics, which will yield three questions: 

Aspect: Robots who are made to be independent, work collectively in
sharing functions yet relying explicitly on human interaction to ``survive''
socially and to derive purpose, from this,
\begin{enumerate}
\item How do socio-robotic colonies form and what are their structures?
\item Are there biological analogues that can be modeled and used to the
project's advantage?
\item Will there be a socio-collective bond between the intelligent machine
and its human analogue?
\end{enumerate}
I believe that with the proper time and budgetary requirements, I
can fulfill the dream of robots closely interacting with humans in
our global society. I expect then, a direct consequence of this, the
porting of technologies to human-machine hybrids such as intelligent
medical devices, replacing biological organs with artificial ones,
and custom-tailored enhancements.

So why hasn't this already happened? Why don't we see robots around
in our cities? I argue that the technology is sophisticated enough
to make a reasonable facsimile of a humanoid-style machine to behave
in a human-like away that would be able to interact. I say it has
already been done in a rudimentary sense within the past five years;
commercial projects such as those out of iRobot and Sony speak volumes
about the technology, so what is holding us back intellectually from
accomplishing it? Is there some unconscious block preventing us from
building robots such as those depicted in science-fiction?

These `reluctances' provide insight into knotty problems; from assaying
the strengths and failures of historical works, I believe the problem
can be rendered geometrically. I will address this later in the thesis.

\subsection{Words}

Not withstanding this general survey, let me now take the time to
examine most closely the specific inspirational sources for this work
and where my notion of choice in the machine as a quantifier for true
artificial life has derived from.

\section{Literature Survey}

I would like to set the scene for this thesis, what has inspired it,
and where it will be going based on some more detailed sources. 

\subsection{Living Systems}

I suppose the most unavoidable direct question is: \emph{What is life?}
Although there are a myriad answers, since this will be a scientific
thesis, the point of view of a physicist seems a reasonable place
to begin. I introduce a essay by Erwin Schrodinger (1944) titled appropriately.

In that a person in cybernetics, in such an encompassing field that
attempts to bring together numerous scientific principles and ideals,
it is truly the attempt noted:
\begin{quote}
We have inherited from our forefathers the keen longing for unified,
all-embracing knowledge. The very name given to the highest institutions
of learning reminds us, that from antiquity to and throughout many
centuries the universal aspect has been the only one to be given full
credit. (Preface).
\end{quote}
And at this point in the evolution of cybernetics in the present era
of the early 21st Century:
\begin{quote}
We feel clearly that we are only now beginning to acquire reliable
material for welding together the sum total of all that is known into
a whole; but, on the other hand, it has become next to impossible
for a single mind fully to command more than a small specialized portion
of it. (Preface).
\end{quote}
Herein lies the quandary experienced by the student of cybernetics,
specifically artificial life. Leaving that the quandary is native
to the field and a pitfall to be wrestled, how is life understood
as a concept? 
\begin{quote}
The large and important and very much discussed question is: How can
the events in space and time which take place within the spatial boundary
of a living organism be accounted for by physics and chemistry? (Chapter
1).
\end{quote}
I offer:
\begin{quote}
Today, thanks to the ingenious work of biologists, mainly of geneticists,
during the last thirty or forty years, enough is known about the actual
material structure of organisms and about their functioning to state
that, and to tell precisely why present-day physics and chemistry
could not possibly account for what happens in space and time within
a living organism. (Chapter 1).
\end{quote}
It is reasonable then, to look toward biological analogues and the
work in the biological and ethological fields wherein to derive hypotheses
with a high degree of reliability and purpose. How is this information
compiled? In other words what is a \emph{quid pro quo} of life relating
to any form functioning in an environment? I quote at length:
\begin{quote}
We are thus faced with the following question: Why should an organ
like our brain, with the sensorial system attached to it, of necessity
consist of an enormous number of atoms, in order that its physically
changing state should be in close and intimate correspondence with
a highly developed thought? On what grounds is the latter task of
the said organ incompatible with being, as a whole or in some of its
peripheral parts which interact directly with the environment, a mechanism
sufficiently refined and sensitive to respond to and register the
impact of a single atom from outside? The reason for this is, that
what we call thought (1) is itself an orderly thing, and (2) can only
be applied to material, i.e. to perceptions or experiences, which
have a certain degree of orderliness. This has two consequences. First,
a physical organization, to be in close correspondence with thought
(as my brain is with my thought) must be a very well-ordered organization,
and that means that the events that happen within it must obey strict
physical laws, at least to a very high degree of accuracy. Secondly,
the physical impressions made upon that physically well-organized
system by other bodies from outside, obviously correspond to the perception
and experience of the corresponding thought, forming its material,
as I have called it. Therefore, the physical interactions between
our system and others must, as a rule, themselves possess a certain
degree of physical orderliness, that is to say, they too must obey
strict physical laws to a certain degree of accuracy. (Chapter 1).
\end{quote}
So a creature with a set of rigorous functionality, i.e. suited to
its environment to a reasonable approximation of regularity or possessing
a homeostatic point:
\begin{quote}
When the dynamic system can vary continuously, small disturbances
are, in practice, usually acting on it incessantly. Electronic systems
are disturbed by thermal agitation, mechanical systems by vibration,
and biological systems by a host of minor disturbances. For this reason
the only states of equilibrium that can, in practice, persist are
those that are stable in the sense of {[}invariance to disturbance{]}.
States of unstable equilibrium are of small practical importance in
the continuous system though they may be of importance in the system
that can change only by a discrete jump. The concept of unstable equilibrium
is, however, of some theoretical importance. (Ashby 1956, p. 78).
\end{quote}
Which shows how physical laws are expressed internally and externally
to the entity considered to be living, with an acceptable range of
what causes can be known and compensated for--stable--and what causes
remain unknown--unstable. This implies the physical phenomena of
order, disorder, and entropy all play a role in the living system;
I would argue whether organic or technic.
\begin{quote}
From Delbruck's general picture of the hereditary substance it emerges
that living matter, while not eluding the 'laws of physics' as established
up to date, is likely to involve 'other laws of physics' hitherto
unknown, which, however, once they have been revealed, will form just
as integral a part of this science as the former. (Chapter 6).
\end{quote}
Leading that not everything (or maybe does not necessarily need to
be known) for a system to 'take on' the form analogous to a 'living'
system, i.e. found in nature and existing as part of an evolutionary
line--an ordered system taking on a lineage of creatures comprising
an evolutional cycle regardless of the origin (known or unknown, \emph{a
priori} or \emph{a posteriori}):
\begin{quote}
The physicist is familiar with the fact that the classical laws of
physics are modified by quantum theory, especially at low temperature.
There are many instances of this. Life seems to be one of them, a
particularly striking one. Life seems to be orderly and lawful behaviour
of matter, not based exclusively on its tendency to go over from order
to disorder, but based partly on existing order that is kept up. To
the physicist -but only to him -I could hope to make my view clearer
by saying: The living organism seems to be a macroscopic system which
in part of its behaviour approaches to that purely mechanical (as
contrasted with thermodynamical) conduct to which all systems tend,
as the temperature approaches absolute zero and the molecular disorder
is removed. (Chapter 6).
\end{quote}
And tied into a living system's status of persistence:
\begin{quote}
It is by avoiding the rapid decay into the inert state of 'equilibrium'
that an organism appears so enigmatic; so much so, that from the earliest
times of human thought some special non-physical or supernatural force
(vis viva, entelechy) was claimed to be operative in the organism,
and in some quarters is still claimed. How does the living organism
avoid decay? The obvious answer is: By eating, drinking, breathing
and (in the case of plants) assimilating. The technical term is metabolism.
(Chapter 6).
\end{quote}
Where for the purposes of this thesis \emph{metabolism} for an artificial
system is the exchange of information and growth of its program complex
in the most rudimentary terms of the concept, which means that an
artificial system is privy to the forces of entropy:
\begin{quote}
...a source of variety such as a Markov chain has zero constraint
when all its transitions are equally probable. It follows that this
condition (of zero constraint) is the one that enables the information
source, if it behaves as a Markov chain, to transmit the maximal quantity
of information (in given time). Shannon has devised a measure for
the quantity of variety shown by a Markov chain at each step---the
entropy---that has proved of fundamental importance in many questions
relating to incessant transmission. (Ashby 1956, p. 174).
\end{quote}
The information flow inside the artificial system would qualify as
incessant transmission and entropy is quantified as the dropping of
bits in a sampling process. As the entity co-exists with its environment,
order is maintained by the input flow of information--negative entropy--creating
a balance or state of theoretical equilibrium that could be calculated
for a given artificial entity.

To leave this part of the survey by a quick summary, what Schrodinger
imports is the look of life in terms of its subsistence and resistance
to entropy or decay. He makes the comparison of a purely mechanical
system, a clock:
\begin{quote}
Let us analyze the motion of a real clock accurately. It is not at
all a purely mechanical phenomenon. A purely mechanical clock would
need no spring, no winding. Once set in motion, it would go on forever.
A real clock without a spring stops after a few beats of the pendulum,
its mechanical energy is turned into heat. This is an infinitely complicated
atomistic process. The general picture the physicist forms of it compels
him to admit that the inverse process is not entirely impossible:
a springless clock might suddenly begin to move, at the expense of
the heat energy of its own cog wheels and of the environment. (Chapter
7).
\end{quote}
The final word is that if we even think of an artificial system as
a purely mechanical thing, devoid of even the most intrinsic bits
of how we philosophically imbue \emph{life}, it can never exist outside
of the definition; i.e. it can never die but simply turn off.

\subsection{Epistemology}

A most fundamental viewpoint of this work is epistemology; without
a framing the discussion, that is, an agreed framework of how new
concepts will be discussed and how they will be manifest empirically,
we will never arrive at quantitative proofs of artificial life. I
quote:
\begin{quote}
Foundational controversies in artificial life and artificial intelligence
arise from lack of decidable criteria for defining the epistemic cuts
that separate knowledge of reality from (supposed) reality itself,
e.g., description from construction, simulation from realization,
mind from brain. When a problem persists, unresolved...in spite of
enormous increases in our knowledge, it is a good bet that the problem
entails the nature of knowledge itself.

Pattee, H.H. ``Artificial Life Needs a Real Epistemology''
\end{quote}
Pattee (1995) writes at length about how life exists and how life
is viewed, the argument he presents is between two limits in the ``cut'':
\begin{itemize}
\item \emph{Life-as-it-could-be} compared with
\item \emph{Life-as-we-know-it}
\end{itemize}
Making the assumption that the failure of artificial intelligence
(AI), evidenced by the Lighthill Report, and its offspring, artificial
life (AL) to rigorously define the millennium-old question \emph{what
is life?} is critical to engineering developments such as the production
of synthetic life forms, e.g., a living system that is independent
of an evolutionary line, Pattee points to the various flaws in the
logic of AI and AL. While agreeing with him during his discussion
of autonomous robotics, I offer the assumption it is the control the
scientist places over his creation, i.e., the formation of a synthetic
life form, is a the root of the failure. In that we lack a foundation
of epistemology wherein to discuss the cooperation of symbols in defining
what is life. I argue it matters little in quantitatively answering
the question; instead, the persistence and evolution of a synthetic
life form and the empirical data resulting from it should be driving
the research.

An ``epistemic cut'' was offered by Professor Sir James Lighthill
where he tried to define \emph{what is artificial intelligence?}
\begin{quote}
The \emph{Lighthill Report} is organized around a classification of
AI research into three categories:

Category A is \emph{advanced automation }or \emph{applications}, and
he approves of it in principle. Included in A are some activities
that are obviously applied by also activities like computer chess
playing that are often done not for themselves but in order to study
the structure of intelligent behavior.

Category B is defined as ``building robots'' and ``bridge'' between
the other two categories. Lighthill defines a robot as a program or
device built neither to serve a useful purpose nor to study the central
nervous system, which obviously would exclude Unimates (sic) which
are generally referred to as industrial robots. Emphasizing the bridge
aspect of the definition, Lighthill states as obvious that work in
category B is worthwhile only in so far as it contributes to the other
categories.

Category C comprises studies of the \emph{central nervous system}
including computer modeling in support of both neurophysiology and
psychology.

If we take this categorization seriously, then most AI researchers
lose intellectual contact with Lighthill immediately, because his
three categories have no place for what is or should be our main scientific
activity - studying the structure of information and the structure
of the problem solving processes independently of applications and
independently of its realization in animals for humans. This study
is based on the following ideas:
\end{quote}
\begin{enumerate}
\item Intellectual activity takes place in a world that has a certain physical
and intellectual structure: Physical objects exist, move about, are
created and destroyed. Actions that may be performed have effects
that are partially known. Entities with goals have available to them
certain information about the world. Some of this information may
be built in, and some arises from observation, from communication,
from reasoning, and by more or less complex processes of retrieval
from information bases. Much of this structure is common to the intellectual
position of animals, people, and machine which we may design, e.g.
the effects of physical actions on material objects and also the information
that may be obtained about these objects by vision. The general structure
of the intellectual world is far from understood, and it is often
quite difficult to decide how to represent effectively the information
available about a quite limited domain of action even when we are
quite willing to treat a particular problem in an \emph{ad hoc} way.
\item The process of problem solving depend on the class of problems being
solved more than on the solver. Thus playing chess seems to require
look-ahead whether the apparatus is made of neurons or transistors.
Isolation of the information relevant to a problem from the totality
of previous experience is required whether the solver is man or machine,
and so is the ability to divide a problem into weakly connected subproblems
that can be thought about separately before the results are combined.
\item Experiment is useful in determining what representations of information
and what problem solving processes are needed to solve a given class
of problems. We can illustrate this point by an example from the \emph{Lighthill
Report} which asserts that the heuristics of a chess program are embodied
in the evaluation function. This is plausible and was assumed by the
first writers of chess programs. Experiment showed, however, that
the procedures that select what part of the move tree is examined
are even more important; i.e. when a program errs it is usually because
it mis-evaluated a final position.
\item The experimental domain should be chosen to test the adequacy of representations
of information and of problem solving mechanisms. Thus chess has contributed
much to the study of tree search; one Soviet computer scientist refers
to chess as the \emph{Drosophila} of artificial intelligence. I think
there is much more to be learned from chess, because master level
play will require more than just improving the present methods of
searching trees. Namely, it will require the ability to identify,
represent, and recognize the patters of position and play that correspond
to ``chess ideas'', the ability to solve some abstractions of positions
and to apply the result to actual positions. It will probably also
require the ability to analyze a problem into subproblems and combined
separate results.
\end{enumerate}
\begin{quote}
McCarthy, John. (2000) ``Review of 'Artificial Intelligence: A General
Survey'{}''.
\end{quote}
My approach during the subsequent pursuit of this thesis will attempt
to derive an epistemology, a way of speaking about the subject and
a manner of defining experiments--coupled with the attempt to ascertain
a reasonable model of synthetic life. In this way, I can begin with
a solid foundation and extend a bundled prospectus of my line of inquiry
and applying to models that have appeared in the history of cybernetics.

\subsection{Models for Consideration}

In casting a glance into the past, I have found the work of W. Grey
Walter to be particularly useful as a means to understand machine
behavior based on physical models of the brain. Water (1953) in \emph{The
Living Brain} talks at length about how, through the lens of cybernetics,
living systems are organized and how they are related to each other.
What is gleaned most exactly is his categorization of artificial life
forms with their biological analogues, in the greatest breadth of
the word. What is crucial and how Walter's work has influenced this
thesis is:
\begin{quote}
...Grey Walter's principled interest in building physical working
models to test hypotheses; and his theories about brain function.
(Holland 2003).
\end{quote}
His strength was in the position that the machines, Elmer and Elsie,
possessed behaviors unaccounted for in his theory, i.e. emergence.
He also expressed the concept of \emph{free will} observed in his
experiments. These two concepts I find intrepid would like to pursue
them in how I would go about solving the problem: postulating theory
and empirical experiment. However, I must first look at researchers
who have reexamined Walter's ``tortoise'' experiments to see if
my ideas of testing choice in the machine under the auspices of Walter's
general body of theory can be supported. 

I point to the work of Owen Holland of the University of Essex. There
are two significant works (among many) to be illustrated here:
\begin{itemize}
\item The Legacy of Grey Walter
\item Could We Build a Conscious Robot?
\end{itemize}
Holland (2003) , poses a critical review of the work of W. Grey Walter's
tortoises, giving sound background information to discussing the technical
aspects of the machines, where science emerged in spite of showmanship,
and he was able to demonstrate via artificial entities the psychological
concept of the \emph{free goal-seeking mechanism.}
\begin{quote}
The first notion of constructing a free goal-seeking mechanism goes
back to a wartime talk with the psychologist, Kenneth Craik, whose
untimely death was one of the greatest losses Cambridge has suffered
in years. When he was engaged on a war job for the Government, he
came to get the help of our automatic analyser with some very complicated
curves he had obtained, curves relating to the aiming errors of air
gunners. Goal-seeking missiles were literally much in the air in those
days; so, in our minds, were scanning mechanisms. Long before the
home study was turned into a workshop, the two ideas, goal-seeking
and scanning, had combined as the essential mechanical conception
of a working model that would behave like a very simple animal. 

Walter \emph{The Living Brain}, p. 125.
\end{quote}
Holland communicates a rich appreciation and great insights into Walter's
machines. I quote a short article by Holland \emph{Elmer the Tortoise}:
\begin{quote}
I knew that in 1949 Grey Walter had built a robot to demonstrate his
ideas about how the brain worked. He did not think humans were intelligent
just because they had ten billion brain cells, but rather because
their brain cells were connected up in many different ways. So he
built his first 'model animal'--Elmer the tortoise--using only two
electronic brain cells, connected together in several different ways.
Not much of a brain, but Grey Walter had designed it very cleverly.
Elmer would explore a room, looking for lights, moving towards them,
circling them, and then wandering off in search of more. If he found
a mirror, he would do a dance in front of it; if he came across his
sister, Elsie, he would dance with her. If he came across an obstacle
he would try and push it out of the way; if this didn't work, he would
go round it. And when his battery began to run down, he would return
to his hutch, and plug himself in to his power socket, setting off
again in search of lights when his battery was fully charged. Grey
Walter had proved his point--two richly connected brain cells were
enough.
\end{quote}
What is striking here is the intention of Walter to reproduce, by
modeling, living systems and that emergent behavior was observed by
the utility of rather simple parts. But was this really true? Was
Walter's work and assumptions independently verified?

Maybe.

What conclusions did Holland reach? I cite--Holland 2003: What what
was Grey Walter the first to do?
\begin{quote}
Walter\textquoteright s list of firsts in biologically inspired robotics
and the related areas is impressive. The tortoises were designed to
test a biological hypothesis about how combinations of relatively
few elements might give rise to complexity of behaviour; they were
probably the first biologically inspired robots of any real interest.
The robots were intended to produce behaviour characteristic of animals,
and Walter was the first to emphasize the importance of behavioural
completeness: 

``Not in looks, but in action, the model must resemble an animal.
Therefore, it must have these or some measure of these attributes:
exploration, curiosity, free-will in the sense of unpredictability,
goal-seeking, self-regulation, avoidance of dilemmas, foresight, memory,
learning, forgetting, association of ideas, form recognition, and
the elements of social accommodation. Such is life.'' Walter (1953,
pp. 120, 121).
\end{quote}
And looking at the tortoises in the light they were working under:
\begin{quote}
The tortoises had to exist in a normal everyday environment, rather
than in some special environment created to take account of their
limitations. He was the first to implement a self-recharging robot.
He made the first observations of emergence in robotics, both in the
sense of the designer being pleasantly surprised at the unanticipated
appearance of some useful side effect of his design, and in the sense
that the interaction of two or more behavioural subsystems could produce
a distinct and useful additional behaviour. The second sense is clearly
demonstrated by several of his remarks in Walter (1960); in fact,
they amount to the earliest formulation of the basic idea of behaviour-based
robotics (Holland 1996). As noted above, he was the first to show
how a robot\textquoteright s actions on an environment could change
it in such a way that the robot\textquoteright s future behaviour
was changed in a useful way, and he was also the first to carry out
experiments in learning on a behaving robot. Because he built more
than one robot, he was also the first in the field of multiple robotics,
showing how the behavioural interactions between two robots of the
same type would produce emergent characteristics of interest if not
utility. He also made the earliest observations in the field of what
is now known as collective robotics: 

``Simple models of behaviour can act \emph{as if} they could recognize
themselves and one another; furthermore, when there are several together
they begin to aggregate in pairs and flocks, particularly if they
are crowded into a corral. . . . The process of herding is \emph{nonlinear}.
In a free space they are individuals; as the barriers are brought
in and the enclosure diminishes, suddenly there is a flock. But if
the crowding is increased, suddenly again there is a change to an
explosive society of scuffling strangers. And at any time the \emph{aggregation}
may be turned into a \emph{congregation} by attraction of all individuals
to a common goal. Further studies have shown that in certain conditions
one machine will tend to be a `leader\textquoteright . Often this
one is the least sensitive of the crowd, sometimes even it is `blind\textquoteright .''
Walter (1957).
\end{quote}
What can I hope to glean from studying, in depth, Walter's work and
Holland's analysis? To what extent did Walter's work influence the
subsequent course of biologically inspired robotics? A point I will
pursue during the course of this thesis.
\begin{quote}
This question is somewhat embarrassing for the robotics community,
because the answer is that it had very little direct influence. Perhaps
the technology of the tortoises was too inaccessible; without a grounding
in the electronics of the post-war world, it can be difficult to understand
how their circuits operate. Perhaps the papers and the book are too
removed in time, tone and style from modernity; The living brain,
in particular, is very old fashioned, but this is perhaps not surprising
when one discovers that it was written by his father, who was of course
educated in the nineteenth century. Many of what are regarded as the
key achievements within biologically inspired and behaviour-based
robotics have involved techniques and observations with which he was
familiar, but which have had to be painstakingly rediscovered in modern
times. His technical priority does not of course diminish the credit
due to the modern investigators, especially since one of his most
important texts (Walter 1960) was first published less than a decade
ago. However, one wonders whether robotics in general, and biologically
inspired robotics in particular, might have advanced further and faster
if his work had not been allowed to fade away quite so fast. (Holland
2003).
\end{quote}
And lastly, how has his influence been felt and is my thinking in
the right direction to understand my models under consideration?
\begin{quote}
On the other hand, the indirect effects of Grey Walter\textquoteright s
work may have influenced modern robotics in a number of ways. The
publicity the tortoises received encouraged many technically inclined
individuals to try and build similar machines; the electronic hobbyist
magazines of the period record many such projects. In particular,
Rodney Brooks recalls attempting to build his own version of the tortoise
after reading \emph{The Living Brain} (Brooks 2002). Later, while
Brooks was working with Hans Moravec on the Stanford Cart, the tortoises
again came to mind:

``Despite the serious intent of the project, I could not but help
feeling disappointed. Grey Walter had been able to get his tortoises
to operate autonomously for hours on end, moving about and interacting
with a dynamically changing world and with each other. His robots
were constructed from parts costing a few tens of dollars. Here at
the centre of high technology, a robot relying on millions of dollars
of equipment did not appear to operate nearly as well. Internally
it was doing much more than Grey Walter\textquoteright s tortoises
had ever done--it was building accurate three-dimensional models
of the world and formulating detailed plans within those models. But
to an external observer all that internal cogitation was hardly worth
it.''

Rodney Brooks, \emph{Robot: The Future of Flesh and Machines} (2002,
p. 30).

Less than a decade later, Brooks\textquoteright s own design principles
were producing simple reactive robots within the new behaviour-based
philosophy. (Holland 2003).
\end{quote}

\subsection{The Simple Conclusion}

I see now that Walter is a solid source of inspiration and a place
to begin my thoughts on my own theories and machines. I will not leave
the position that the natural world is an inspiration for efficient
problem solving and will discuss what will seem to be contradictory
arguments of artificial systems that mimic biological counterparts.
I will not argue for each in their totality, but as branches of the
foundation wherein to explore if a mimic-purpose machine, i.e., a
mechanical owl can be made
\begin{enumerate}
\item to behave like its natural analogue in a close an approximation as
possible (where available), and,
\item allow the machine to develop independent behaviors as a consequence
of its own experience by making choices.
\end{enumerate}
while simultaneously serving to give insight into how an artificial
system would evolve in its ``genetic'' isolation while cooperating
with other entities in an environment within the range of its experiential
ability. But where does it all rest? I will argue the dynamics of
choice and by quantifying them, a series of study can unfold to get
at least the smallest definition of \emph{free will} and what it means
to artificial systems and their adaptation strategies in a tangible
environment in the operational paradigm described and used by Walter.

With that, I now will turn to discussing the compendium of my body
of theory and expression called \emph{The Method of Artificial Systems}.

\section{The Method of Artificial Systems}

Section Overview: I will start with the basic premise that nothing
of relevance to the topic of this thesis can be obtained absent of
a cohesive method of expression that will guide all subsequent depictions
and models derived as such. I will make a series of arguments designed
to illustrate my thinking processes regarding this subject. My first
argument is I believe that if a machine is given the ability to make
choices and as a consequence of those choices, possesses the feature
of the direct experience of entropy, it will foster emergence, manifest
behaviors not accounted for in theory or experiment. \emph{Choice}
is the key word and will be used as an epistemological foundation
for theoretical and experimental manifestation of what I propose in
this thesis.

\subsection{Method of Expression}

It is an expression of the method that the manifestation of the machine
in independent articulated form should be autonomous and not privy
to interference in learning categories and behaviors from an active
outside entity. It consists of three methodological assumptions and
the resultant questions that are firstly derived from them.

Method \#1: If a machine can be made to mimic biological life, it
has access to those kind of experiences attributed to it.

Resultant \#1: Will the empirical ability to make a choice and possess
knowledge of it foster richer behavior motifs?

Method \#2: If a machine can make a choice, it portrays some level
of consciousness. 

Resultant \#2: Does the notion of free-will and the power to make
choices foster a rudimentary sense of self-awareness?

Method \#3: If a machine has knowledge of its death, it fosters emergent
behavior.

Resultant \#3: Does the placing of a polar opposite to life preclude
an organism to conspire against it?

In order to develop a clear picture of methods concerning my inquires,
I will attempt to balance my assumptions with clearly defined concepts
from historical renderings as well as those arriving from my own experience.
Although neither can be absolutely quantified, where possible I will
qualify by juxtaposition with established tenants such as those realized
in ethology, fuzzy logic, finite state automata, and self-constructors.
It is my sincere hope to explicate a template by which artificial
beings can be realized in technology, a set of laws can be authored,
and wherein future generations can be established based on a ``foundation''
theory. I see the current state of AI / AL as a patchwork of theories,
experiments, and realizations and I would like to introduce a unified
language weighted with concepts narrow enough to allow complex machines
to interact with human societies.

\subsection{The Choice Methodology}

The tenets of biologically-inspired robotics are founded on the principle
of robots who mimic typified life forms\cite{key-8}. The foundation
is divided into two principles:

1. Attempts to create functional robots based on living systems, 

2. Creating robots to understand biological systems\cite{key-3}.

Let's take a look at the methodological assumptions listed in ï¿½2.1:

Method \#1: If a machine mimics biological life, it has access to
those kinds of experiences attributed to it.

The arguments in this thesis are engaged in the first principle since
I am interested in creating functional, autonomous robots who can
subsist for themselves in an environment free from human intervention.
To this end, the machine must resemble a natural form and function
in some sense of the words to make it recognizable when viewed by
a participant. In order to necessitate forms and functions, a typography
of life forms is required to ascribe relevant behavior necessary to
the type of machine desired.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/cognitionHierarchy.jpg}

\caption{A Cognition Hierarchy}

\end{figure}

Figure 1 represents a hierarchy of available objects of the systems
comprising a planetary body, in this instance a closed system. It
is organized by decreasing emphasis in ascribed intelligence. I have
divided the continuum of life into three major categories: Cognition,
Instinct, and Inert. Within the categories are sub-categories contrasted
by their inherent complexity. For example, in the cognition group,
humans are at the top of the hierarchy because of their contrasting
complexity to the other members in the group. Androids are lesser
as they are designed to mimic humans but are not necessarily privy
to the level of complexity manifest in humans, however, dependent
upon the level of technological development. Robots and automatons
fill the rest of the category as they are less complex than androids
but more complex than the members of the instinct group. At the top
of the hierarchy of instinct systems are animae. Animae are synthesized
animals. Ideally and dependent upon the cleverness of the programmer,
they are more complex than the other members of its group. Animae
can be in the form of cats, dogs, or other synthetic animals. Animae
is a noninvasive place to start investigating questions of the properties
of what constitutes a synthetic life-form; they are complex enough
to inspire interesting research questions. Currently in artificial
intelligence, these pursuits are done in instinct systems which may
or may not yield interesting enough results for purposes of artificial
life. However, it still may be of value, high enough in the list to
try to understand agents, particulates of intelligence, as a function
of automata entities in computing environments. It should be noted
that a third system does exist within the frame of this definition,
the inert. In a physical sense, the inert plays only a peripheral
role to both systems; however, in an abstract sense, the inert plays
a crucial role in establishing a closed-loop context. It aids in ascribing
and formulating behavior and choice strategies of the other two systems.
In such a view, it is a third-party. Intelligence is ascribed as a
sub-property of each system and arranged in a hierarchical form by
the entities that fill each of them. This arrangement is by no means
authoritative but serves to illustrate the difference between organic
and inorganic systems and where the concept of life may be empirically
understood.

For the purposes of the research, I make the assumption that cognition
is a state of self-actualization\cite{key-9}. We, as humans, know
this phenomenon only from our own experience and can only approximate
the experience of others, including other types of living systems.
This, however, should not prevent a broader definition since our degree
of approximation is limited by the definition itself. Firstly, there
is a line of demarcation between a cognitive system and an instinctive
system. A cognitive system is the result of a complex evolution of
an individual's experience and an instinctive system is the result
of the propagation of genetic information between generations of living
entities. Secondly, a cognitive system has the ability to extend beyond
the quantity of genetic information of an instinctive system and expresses
a qualitative difference. Thirdly, this qualitative difference gives
rise to two equal yet distinct states of being---the high mind and
the low mind. Therefore, cognition is the ability to direct changes
on continuous events. Instinct is the inability to cognitively affect
the outcome of continuous events. Although there are anomalies that
may traverse the definition dependent upon empathetic qualification,
I argue it holds for most entities.

\subsubsection{Analysis Toolbox, Part A: The Choice Complex}

Method \#2: If a machine can make a choice, it portrays some level
of consciousness.

The question regarding choice is: can a machine make a choice and
if it did, would it be a meaningful one? On the condition that artificial
life is no different that organic life, if an organism is dependent
upon its survival and purpose, i.e., obeys the law of entropy, then
it must by default make choices regarding the success or failure of
its species. This mechanism is the characteristic theory of evolution\cite{key-10}.
If a species could not make the proper choices, adapt to changing
conditions, then it will become extinct. This feature needs to be
extended to artificial life forms to see if the quality of artificial
life is real or an imagined property in cybernetics. I argue this
is the only way to know for certain whether or not the forms are alive
and prone to the forces of evolution. An architecture should be designed
that sets the purpose of the machine and its behavior as an emergent
property exhibited in its choices.

How is behavior generated from architecture, how can the intellectual
link be made? I argue that I can test scientifically the concreteness
of a finite system comprised of a series of choices that determine
life or death. I extend this argument to synthetic machines for if
they are to be considered truly alive, then they must obey the basic
condition that they can die and that they have knowledge of it. In
biology, this trait of death is of a decreasingly loss of faculties
or entropy, or in physics, the decay of energy in a system.

In the case of choice, there is the work of William Grey Walter. His
experiments were the result of his curiosity of how the brain resulted
behavior. To this end, he constructed three-wheeled automatons donned
with lights that searched out other lights. They were analog devices
which used triodes and amplified feedback to mimic types of behavior.
The feedback between the circuits caused the machine to display four
distinct types of behavior qualified by the observer. The problem
with Walter\textquoteright s analysis was that many of his assumptions
were not tested outside of his own research and when they were in
the late 1990s by Owen Holland, many of Walter\textquoteright s assumptions
were wanting\cite{key-3}. However, what is interesting here is Walter\textquoteright s
notion of 'free-will', or choice, exhibited in his machines.

In commentary from O. Holland:
\begin{quote}
In his writings about the tortoises, Grey Walter gave much weight
to an attribute he called \textquoteleft internal stability\textquoteright \footnote{Walter borrowed this concept from his contemporary W. Ross Ashby who
performed an exhaustive treatment of it he called the homeostat.\cite{key-12}}---the claimed ability of the tortoises to maintain their battery
charge within limits by recharging themselves when necessary. A feature
of the tortoises\textquoteright{} circuitry was that, as the batteries
became exhausted, the amplifier gain decreased, making it increasingly
difficult to produce behavior pattern N (negative phototropism). Holland
(2003, p. 2108-9) 
\end{quote}
Which is the attribute to avoid the light in the charging station
where the \textquoteleft feeding\textquoteright{} took place\cite{key-8}.
I am extending this notion to the theory presented in this paper and
postulated experiment.

Method \#3: If a machine has knowledge of its death, it fosters emergent
behavior.

This theoretical assumption is simple: If a machine know it can die,
this knowledge and direct access in manipulating it physically, will
cause emergent behavior. Emergence is a property apart from the collection
of quantification of its parts. In the following section, I will delineate
a design that will facilitate the principles set forth in this methodology.
Physically, this is realized in what I call 'The Entropic Circuit'
which will be introduced in ï¿½4.2.2.

\subsubsection{Analysis Toolbox, Part B: Architecture Theory and Design}

The design of the artificial life system is firstly defined as a series
of goal-based assumptions that guide the development of the methodology.
I will outline a set of four goals that will foster a successful synthetic
animal or animae.
\begin{enumerate}
\item The first goal of a successful cybernetic system is that it should
be fully autonomous. That is, once the system is started, it should
require no further input from an external source or operator. In order
to be autonomous, the system should be self-sufficient; i.e., have
all the components necessary for its operation installed, variable
in component and configuration depending on the expertise of the engineer.
But when the system is brought online, it should run continuously
and without fail.
\item The second goal of a successful cybernetic system is that it should
exist in situ or in context with its environment. It must be able
to access experience from a native stimuli-response model with which
to compose unique algorithms.
\item The third goal of a successful cybernetic system is that it should
possess a system of behaviors relevant to its being. It should also
have the ability to evolve and eventually reproduce.
\item The fourth goal of a successful cybernetic system is that it must
be in behavior indistinguishable from any other living system it mimics.
\end{enumerate}

\subsubsection{Analysis Toolbox, Part C: Automata- and Agent-Based Domain Considerations}

Automata-based systems are the core of the programming domain. They
serve not only as descriptors for the system logic, but for matters
of reflection as well. Automata are most powerfully realized in the
architecture of both the hardware and software design paradigms and
it is here where they will be more directly applied. As automata can
lack the appropriate control factors, it is the introduction of agents
that will express this desire in the software code.

Agent-based systems are also being considered as they possess the
required features in their functional programming tasks: they have
the ability to acquire data from sensors, express that data in code,
and can act upon it by using effectors, which are simply a sensor
device that has an I/O capability such as vision or movement. They
are best deployed as efficiency monitoring programs concerned primarily
with system robustness. As the new architectures are developed, the
will be explored and deployed to delineating the analysis of choice
and the subsequent discoveries deriving from it.

\subsection{The Problems Under Consideration}

This thesis can be broken down into the study of the following problems:
\begin{enumerate}
\item The Problem of Energy
\item The Problem of Communication
\item The Problem of Coordination (Control)
\item The Problem of Raw Materials (Construction and Reproduction)
\end{enumerate}
These problems will be delved into at different points in this thesis
by references to various features present in the designs I proffer,
the theories I propose, and the postulates I suggest. I firmly argue
that all research into aspects of AI / AL fall into one of these four
problem-categories.

\subsection{The Conclusions}

The combinatorial and multi-faceted approach will yield successful
results. 

\section{Orchestration and a Feature of Choice}

Section Overview: This section addresses the research question: Can
a machine make an aesthetic choice based on a nondeterminate conditioning
in a collected and coordinated learning environment? Coordination/Orchestration:
Robotic colonies are becoming of more interest and of more value technologically
than other problems in automation. It is the task represented in the
concept of orchestration that is of non-trivial interest in this paper.
Here there will be an honest attempt to insure the problem is NP-complete
and exhaustive of the purposes outlined here. However, briefly stated,
most of the efforts classified as AI or AL will be concerned with
constructing automata- and agent-based programs.

\subsection{What is Orchestration?}

Defined simply, orchestrated robotics is a means of distributing energy
and information across a network of social robots. The caveat here
to note is the distribution of energy clause\footnote{The first problem under consideration from ï¿½2.3.}
which, in order to be true orchestration, must contain a central computing
complex\footnote{The second problem under consideration from ï¿½2.3.}
and a series of mobile automatons that exchange the power and information
wirelessly\footnote{The third problem under consideration from ï¿½2.3.}.
Such an enterprise can be complex and, in terms of physics, it relatively
is; I say 'relatively' because once one grasps the basic concepts,
it is understood that extending them to multiples and a means of achieving
a wide enough resonance width wherein the power is transferred and
acts as a carrier for information can pass through at the appropriate
distance is a powerful solution. However, realizing that the orchestration
might exceed the limitations in the middle range exchange factor of
the transmission, the use of transponders seemed a reasonable solution.
They are simple: binary and trinary coils with large surface area
antennas to pass the signal to the robots extending the mid-field
and reducing the work required by the core to generate less stable
signals in the far-field.

It is highly advantageous to apply agents which would mitigate the
architecture of the system and execute a program based on the locations
given to them through their percepts and sensors, perpetuated though
their effectors and actions. 

Orchestration in this unique instance takes the form exhibited in
the following figure:

\begin{figure}[H]
\includegraphics[scale=0.75,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/QDTransGen.jpg}

\caption{\label{fig:orches}An Orchestrated Robotic Network}

\end{figure}

Such a system would be capable of operating in remote or hostile environments
too dangerous for humans while at the same time compatible socially
to cooperate internally and externally with those providing the system
directives and instructions. 

\subsection{Choice Featured Runtime}

The feature of choice can be measured as a consequence of causality,
what reactions were observed following certain empirical actions.
Coordination at runtime of a robotic colony controlled by a centralized
computing machine (e.g., the queen) engaged in a many-parallel I/O
with worker robots (e.g., the drones) not dissimilar to colonies of
this type seen in the wild is the first step to understanding orchestration.
Some examples include bee or ant colonies. The problem can be broken
down into its component sets by following the biological models and
mimicking them in technology.

\subsubsection{Choice Features}

There are a deterministic set of features which can be obtained by
quantifying behavior in the relativistic natural system considered
for replication. Features present in the natural system can necessarily
be considered for replication if they can be quantified into an automata
state-machine logic.

Choice is narrowly defined as a pathway entity toward a goal-seeking
behavior. Behavior is defined as a collection of choices requisite
to a pathway solution dependent upon environmental factors weighted
by an acasual mechanism called free-will. Testing these paradigms
is irrelevant as these systems can be widely observed in nature; however,
quantifying them into a software domain is a non-trivial task.

\subsubsection{Choice Quantification}

There must be two features in tension against one another to allow
choice:
\begin{enumerate}
\item Instinctual runtime,
\item Cognitive runtime, whether a conscious or unconscious stub.
\end{enumerate}
These two parental categories rely on the creation of events to flow
from one state to another; these events are either triggered by external
or internal stimuli. Each state is available for analysis at any linear
time by reflection into the code blocks created as a function of the
placement of them at the time of creation, and as a function of reaction
to external stimuli. The culmination building a unique new feature
which replaces the previous state. This is called experience. Each
experience is contrasted by the tension between the two parent categories
based on range governance (see ï¿½5.3.7) and through feedback, presents
a cognitive workflow which is a hybrid of the two original features.
However, a caveat of the system is that the hybrid state cannot be
subject to analysis within the host system; instead, it must be analyzed
by impassive observation initialized by a third party resource.

This precludes that in order to study choice in quantified terms looking
for the \emph{motivation} of the choice and not the assemblage of
choices themselves, that several individualistic or autonomous systems
must be harmoniously cooperating in some sort of orchestration. This
eliminates most robotic systems now in use that look only to autonomy
and social interaction; this also eliminates most of the adaptive
machines currently under experimentation. I argue in this draft setting
that hive-based automata state machines are the only structures able
to withstand the conditions of stress in the environment and are subjected
to the forces of evolution with as much import as their natural counterparts
to human societies.

\subsection{The Relevancy of The AI Problem in Orchestration}

AI systems are classified into one of four categories:
\begin{enumerate}
\item Systems that think like humans,
\item Systems that act like humans,
\item Systems that think rationally,
\item Systems that act rationally.
\end{enumerate}
Although there is some fuzziness that exists between the types that
are exploited in this thesis, conditioning the relevancy of the problems
I mention will not be.

\section{Testing Choice: The Robot and Featured Power}

Section Overview: This section is divided into two distinct categories,
the robotic platform, responding to the Problem of Energy\footnote{Please refer to ï¿½2.3.},
and the onboard system inclusive of hardware and software. The onboard
systems will be further divided into subcategories of platform hardware\footnote{Relevant to Problems \#2 and \#4 of ï¿½2.3.}
and system software\footnote{Problem \#3 of ï¿½2.3.}. Featured power
is a generalized term that expounds upon the conditions set forth
at the beginning of this thesis and inspires a control system based
on the parameters it allows for. 

\subsection{Featured Power}

I offer the following experimental design to empirically test the
notion of choice, survival, and the possible consequence of emergent
behavior. I designed the Featured Power Environment (FPE) as a means
to substantively give the machine the ability to make a choice between
types of operational power necessary to its onboard components. The
hardware design is based on transformational, structural logic approach\cite{key-12}.
I argue that an understanding of such a transformation logic system
will illustrate empirically the relation of choice to behavior in
the machine and to test whether or not the notion of the survival
complex is a mechanism that will lead to emergent properties. The
general schematic of the system is illustrated in Figure 3.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/featuredPower.jpg}

\caption{Featured Power}

\end{figure}

The waveforms to the left of the figure are a spectral view of the
transmission representing the total power in watts. The spectral forms
are real power to be consumed by the machine. Depending on its current
task and necessary power to perform its programmed task, the machine
is allowed to estimate its consumption and make a choice as to the
type and amount of power it needs. Listed to the right of the figure,
Level \textquoteleft A\textquoteright{} is the highest power level
energising all onboard systems. \textquoteleft B\textquoteright{}
is mid-range powering motor functions and a some sensors. \textquoteleft C\textquoteright{}
is sleep mode. These three hierarchical functions form a trinary computational
system in addition to the more generalized binary modes of the generic
computing device.

There are three modes of operation for the device shown in Figure
3. Sleep, average, and high power represented by C, B, and A respectively.
At a given time, the machine receives a level of power necessary for
its operation. For example, if a general-purpose robot has a power
consumption rating of 15VDC with a current draw of 0.125A, it is necessary
to calculate the consumed power at an instantaneous time in watts: 

\begin{equation}
P_{s\text{}}=ExI
\end{equation}

Considering the type of transmission and the necessity to transmit
only the proper amount of power, a pulsed system would be preferred
to a constant wave (CW) system to have the machine consume power at
intervals instead of in a stream\cite{key-13}(438-43). Nevertheless,
a pulse period of 10$\mu$s should suffice to power onboard components.
Clock speed of the processing bus (for example 1 MHz) should be made
to agree with the pulse period to keep the power flow symmetric with
its computational speed. In this way, unless the power is used by
a loaded circuit, it will not transmit more than the quantity we have
set for it by the frequency of the wave. For example, the power of
each waveform is:
\begin{quote}
Waveform A: 15 volts x 1.0 amperes = 15 watts,

Waveform B: 15 volts x 0.500 amperes = 7.5 watts,

Waveform C: 15 volts x 0.200 amperes = 3 watts.
\end{quote}
In the early part of the experiments, I will expect to send a higher
quantity of power than what is anticipated by the system. This is
to account for loss in the transmission. The method is prone to some
leakage and specific features of the utility of the prototype will
be included in ï¿½4.3. Briefly, though, it is advantageous to choose
a carrier frequency and have the bandwidth resonance include the likelihood
of feedback, allowing messages to be included on the transmission.


\subsubsection{The Robots under Test}

This system has been designed to fit with \emph{any} type of robotic
system currently on the market and inclusive of those machines under
development for future release. If what is discussed and subsequently
deployed cannot be made universal, then I argue it is worthless. Subsequent,
then, there are two different kinds of robots under test:
\begin{enumerate}
\item Generalized platforms,
\item Specific components (hardware and software).
\end{enumerate}
I will discuss these types in the following sections and delineate
how each are interconnected to form complex loops that can aspire
for a rich tapestry of intention, response, and behavior. 

Although philosophically I ascribe to Platonic dualism, I will not
argue for emergence based on these or other philosophical treatments.
In contrast, I would like to see such a feature quantified with rigid
experimentation and proof. However, I cannot discount the appeal of
a system that experiences an inner world of metaphor and imagination
not unlike ourselves--if only given the freedom to allow for it.
Therefore, while I will strive in the belief that a system complex
enough experiences emergence directly, I will not anthropomorphize
the features I argue. Instead, I will use them as the driving force
for the abstractions in software coupled with the ability of the machine
to make its own choices regarding whether or not to implement such
conditions directly. It is for future research on tangible machines
where such fuzzy concepts can be better illustrated to a wider audience.

\subsection{Robotic Software Abstractions}

Based on ï¿½3.2.2, the necessary software abstractions are the meat
of this work and the works that will extend beyond it. At the time
of writing, these abstractions are rigidly-defined but loosely-coupled
to real-world interface development environments (IDE). However, these
abstractions are well-understood in an empirical sense and will find
their way into software as the technology allowing for their functions
to come to fruition. 

\subsubsection{How Successful software abstractions can lead to interactive machines.}

The Software Paradigm

The software architecture possesses the same transformation-logic
array of the hardware model. The software paradigm is a modular, domain-specific
programming language; it parses, sorts, scripts, compiles to objects,
transforms, and generates input and output channels. A domain-specific
language (DSL) is created specifically to solve problems in a particular
domain and, in the general case, is not designed to solve problems
outside of it. In contrast, a general-purpose language (GPL) is designed
to solve problems in many domains with an extensive toolbox that does
not necessarily focus on the specific case. Many DSLs do not compile
to byte-code or executable code like GPLs, but to various kinds of
objects. DSLs have exposed APIs that can be accessed from other programming
languages without breaking the flow of execution or calling a separate
process. Thus, they can be designed to operate as programming libraries\cite{key-14}. 

\subsubsection{What kinds of abstractions are we talking about?}

Functional libraries derived from abstractions in automata-based programming
corrected and moderated by agents. This insures an onboard self-correction
mechanism in place in the earliest prototypes that can report the
internal homeostasis point in order to generate scientific data. From
the earliest works, the data can then further the advance of studies.
These sections will be better supported in future versions of this
draft.

\subsubsection{How independence can insure long-term perpetuation of intelligence.}

Autonomy is a fundamental foundation of intelligence which will be
emphasized at the duration of this work. 

\subsubsection{Learning survival at the cost of existence--The Entropic Circuit.}

One of the most striking features of this design is that experiments
can be conducted continuously and without limit. As long as the transmission
system is powered, the machine will remain online. In this way an
equilibrium can establish a baseline between life and death. If the
machine does not make the right choices to enhance its survival, it
turns off and effectively dies. If it does not send the proper signal
to the transmitter, it will not receive the proper power. A small
capacitor contains enough charge to keep it active for a 90k mS countdown
once the power is too low or not available for it to further perform.
The experience gained from its life cycle is held in a volatile memory
device that will be erased if the power is off. An additional strength
of the design is since it remains online continuously, observation
of long-term behaviors can lead to advances in understanding artificial
ethological concepts in the model under examination. The physical
realization of entropy is designed to be an add-on to the existing
general robotics platform. Called the Entropic Circuit, it is part
of what I term a domain-specific robotics platform, similar in breadth
and scope to a domain-specific computing language. It is illustrated
in Figure 4.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/entropicCircuit.jpg}

\caption{The Entropic Circuit}
\end{figure}


\subsubsection{Scenario Coding}

A notion discovered during the research of this thesis is a concept
called 'Scenario Coding'; this was created to allow for the increasing
levels of complexity realized in software programming. Scenarios,
or programmatic layouts, are similar to the creation of landscapes
in artistic or engineering activities.

Scenario coding is a concept I imagined as a consequence of reading
fiction or listening to music and coming to the understanding of the
substance 'between the words', i.e., the inherent meaning extracted
from the words, enhanced in some cases by distinctive music at certain
tones designed to give the reader / listener an experience. Casually
noticing that a combination of sensory input patterns can inspire
a richer experience that each independently and in some cases enhance
intelligence through stimulation of curiosity driving ambition, I
wondered if I could capture the essence of 'between the words' in
a software archetype. It this aesthetic that I would like to somehow
contain in a logical programming domain in a variety of contexts as
discussed in this thesis.

I will leave this subject for now and continue to pursue it as my
education continues. Next I will address more physical designs, experiments,
and some proposed avenues to proofs I anticipate I will traverse.

\subsection{Wireless Power: The Queen-Drone Transmission System}

The idea of what I call 'The Queen-Drone Transmission System' stems
from a series of prototypes constructed between the years 1996 - 2004.
The most influential of these was the Model 'F' Wireless Power Unit
built January to April 2004. Based on Tesla's wireless patents \#645576(US),
'System of Transmission of Electrical Energy' and \#723188(US), 'Method
of Signaling' the prototype showed that a sufficient amount of power
in the form of an electromagnetic carrier wave could be transmitted
from point to point powering a small off-the-shelf robotic called
'i-Cybie'. As further investigations and tests were accomplished,
I discovered that the transmission was mathematically rendered using
a calculation of areas. The power was distributed over an area dependent
upon the surface area of the transmission pad and a summation of the
receiver pads. Barring leakage (transmission loss), the total receiver
area was proportional to the transmission area forming a linear relationship
between them. What proved to be the most interesting aspect of this
work was the discovery that signals could be passed between a central
core (a queen) and a series of smaller mobile 'worker' robots (drones)
allowing for more complex hardware and software configurations forming
the basic of orchestration, a novel and strongly defined concept in
this thesis. Although not well understood experimentally, it is for
the work to be conducted while researching this thesis, to conduct
the experiments, render findings, and publish results. This requires
the input of funding as well as laboratory space; it would be of substantial
interest to generate monetary assistance from the European Union (applied
for June 2007) to gain experience and develop this unique technology.

A discussion of the system in relevant to illustrate how the theories
of examination, relevant to creating a computational model, have been
conducted leading to the proposed comprehensive prototype.

The Model 'F' is a mulitvariable electromagnetic field generator,
the principle of which, has been captured by a research group at MIT\cite{key-16}
providing an independent proof of the viability of this type of technology.
Such a system was exemplified by Asimov\cite{key-17}, as an inspiration
and visualization exercise, it helps to objectify the machine. Figure
5 is a picture of how the MIT system works; the Model 'F' and the
Queen-Drone system behaves in a similar manner save that my system
can additionally carry information to waiting groups of machines.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/MIT-Witricity.jpg}

\caption{The WiTricity (MIT) Transmission System}

\end{figure}

My intention was to use my prototype to power a robot whose power
demands would rise and fall dependent upon the work done. This meant
that the voltage would stay relatively constant, but that the current
would change. The thin winds of the spiral couldn't generate enough
energy at the surface as the impedance was quite high. I discovered
a solution that would allow the power to transmit through a third
coil and allow me to embed its receiver inside the robot itself, replacing
the battery pack. The Model 'F' wireless power transmission system
is illustrated in Figure 6:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/model-f.jpg}

\caption{The Model 'F' Transmitter}

\end{figure}

And the i-Cybie battery compartment showing the card installed (Figure
7).

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/cybieInstalled.jpg}

\caption{i-Cybie and Receiver Card}

\end{figure}

The original Tesla system transmitted power from transmitter (Tx)
to receiver (Rx) only. Both systems used rather large spiral coils
(around 40cm in diameter) and were too large to be hauled around by
a robot. I understood that if the spiral windings could be tied to
linear coils, they energy could be transferred at higher power and
introduced the coil (B) on upward shaft in the center of the spiral
in agreement with the operational band of the tuned system. This meant
there was a third component of the design; power would travel in the
same manner, from spiral A to spiral A\textquoteright , but the magnitude
of the energy was shifted in phase to an ancillary card onboard the
i-Cybie (Figure 7). The operational frequency was set to 78MHz, the
amplitude to 24VAC at .125A, which was enough power to provide 6VDC
(1.15 to 2.80W converted by external circuitry) necessary for the
robot\textquoteright s operation. Operational threshold was a maximum
of 50VAC at 0.06A.

While conducting these experiments, I discovered that the behavior
of the wave was a function of the space inside the receiver bay and
not a direct function of the surface of the coil. I had to revisit
my extrapolation of the theory and take a look at how I was describing
the geometry of the system architecture.

\subsubsection{The Geometry of the Problem}

Consider a transmission \emph{space} equally divided into geometric
blocks in three-dimensions, a container, as illustrated in Figure
8:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-7.jpg}

\caption{Blocked Spaces}

\end{figure}

Within this space lies the intersection of three planes representing
the charge surfaces of the vectors of the transmission waveform:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-8.jpg}

\caption{Transmission Planes}

\end{figure}

That intersect with the geometric blocks according to the number of
surfaces available to interact with the planes lying along each trajectory.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-9.jpg}

\caption{Container Slices}

\end{figure}

Each of the slices is organized by their orientation to the planar
axes. For example, slices oriented along the x-axis would absorb energy
from the planar wave traveling along the x-direction. The slices are
from the top, middle, and bottom of the cubic structure. Slices oriented
along the y and z-axes would absorb energy from the planar wave traveling
along the y and z-directions. The equation describing this relationship
is a simple algebraic representation:

\begin{equation}
\hat{X}=l(x)\cdot h(y)\cdot w(z)
\end{equation}

Where:

\begin{equation}
l(x)=4,h(y)=2,w(z)=3
\end{equation}

Solving this relationship provided the value of 24cm$^{\text{3}}$.
To calculate the effectiveness of the space as a measure of usable
charge density, I need to calculate the number of non-redundant slices
in the container. For that I use the formula:

\begin{equation}
X_{s}=(l\cdot w)n_{h}+1
\end{equation}

\begin{equation}
Y_{s}=(l\cdot h)n_{w}+1
\end{equation}

\begin{equation}
Z_{s}=(h\cdot w)n_{l}+1
\end{equation}

Solving:

\begin{eqnarray*}
X_{s}=36, & Y_{s}=32, & Z_{s}=30
\end{eqnarray*}

There are 98 non-redundant two-dimensional surfaces in the container.
The next step is to alter (2) and multiply the solution by a potential
given by the rating of the robot's battery potential:

\begin{equation}
\phi_{T}=\frac{\rho}{\psi}[X_{s}+Y_{s}+Z_{s}]
\end{equation}

Where $\rho$ is measured in volts and $\psi$ a dimensional factor.
Solving the equation at the potential of the i-Cybie:

\begin{eqnarray*}
\phi_{T}=588V
\end{eqnarray*}

The solution is valid only at a fixed point when the system is asked
for a measurement. Within the transmission environment, the equation
behaves as:

\begin{equation}
\phi=\frac{\rho}{\psi}\int(X_{s}+Y_{s}+Z_{s})dt
\end{equation}

Disseminating the planar waves along each of the quantiles aligned
with the coordinates in the Cartesian system:

\begin{eqnarray*}
a=\int36x\,dx, & b=\int32y\,dy, & c=\int30z\,dz
\end{eqnarray*}

Solving:

\begin{eqnarray*}
a=18x^{2}, & b=16y^{2}, & c=15z^{2}
\end{eqnarray*}

The use of the indefinite integral defines the finite values within
it as the system is not infinite. What do the integrals look like?

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-14.jpg}

\caption{Mapped Integrals}

\end{figure}

As expected, each is a parabola. Since the system's core equation
is generating a parabola, it is a non-trivial to visualize in a polar
grid which here is especially useful where we want to express the
relationship between points--translated into areas--expressed in
terms of angles and distance for a spherical coordinate system in
three dimensions, which in this case, is a spiral:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-15.jpg}

\caption{Characteristic Spiral}

\end{figure}

However, the system is a little more complicated than that and would
be served better if a governing or characteristic equation could be
discerned.

Consider an Archimedean spiral r$_{\text{s}}$ with a number of turns
\emph{n} where the distance \emph{s} between each of the arcs is constant,
that is, dependent on some relation of \emph{\ensuremath{\int}n dn}.
The mean capacitance $\overline{C}$ on the antenna increases with
\emph{n} as well as the mean impedance $\overline{Z}$ over a nearly
constant transmission time \emph{t}. The equation governing this system
is:

\begin{equation}
r_{s}=\sqrt{t}-t-n
\end{equation}

The inner radius is given by:

\begin{equation}
r_{i}=\sqrt{t}-n
\end{equation}

A more accurate representation of the system, now under governance\footnote{The principle of a functioning dynamic system must obey a core or
characteristic equation that determines its array of subsequent behaviors.} appears as:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/optimizedSpiral.jpg}

\caption{Optimized Spiral}

\end{figure}

Which is not unlike the physical windings of the system. I now want
to assemble a composite solution and find an implicit solution to
the equation with the right-hand side being equal to the potential
of the system such that:

\begin{equation}
18x^{2}+16y^{2}+15z^{2}=588
\end{equation}

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/f2_files/1-16.jpg}

\caption{The Waveform}

\end{figure}

Inputting different stimulus values at the receiving port of the transmitter--\#4
in Figure 6--shows the system is susceptible to range limits for
differing values of $\phi$. 

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/fsxRange.jpg}

\caption{Range Limits}

\end{figure}

Which demonstrates it is a closed system at a specific resonance bandwidth
which I recommend be studied in greater detail as this work progresses.

\subsubsection{The Role of the Queen in the Colony}

The queen represents a centralized computing complex that contains
all the substantive hardware and software necessary to drive the system
forward in operation, task, growth, evolution, and generational advances
in the form of a rudimentary form of reproduction. A parameterized
device, it responds to the programmed core of its design, behaviors,
and paradigms without deviating beyond the bounds of a governing apparatus
such as a bounded equation. This 'fail-safe' is built into the system
to prevent undue or erratic evolution extending the colony beyond
its intended purpose.

\subsubsection{The Role of the Drone in the Colony}

The drone represents a singular entity replicated in orders of hundreds
or thousands to fulfill the role, task, and purpose of the colony.
Contrasted with a single queen, they carry only the components necessary
for their given tasks as created when the system was originally designed
and proposed for operation, behavior, and environment.

\subsubsection{Choice \& Orchestration}

These two concepts are irrevocably tied together and form two parts
of a symbiont circle in this system. More to come.

\section{Results and Discussion}

Section Overview: Here I examine how to employ the data gather from
experiments to support my hypotheses.

\subsection{Numerical Components of the Theory}

What constitutes the numerical domains of the problems discussed in
this thesis are those dealing primarily with problems similar to those
found in geometry, topology, anthropology, physics, and computer science.
Each numerical relationship is derived from the balance between the
machine under analysis and the human interacting with it forming a
closed system subject to definable rules and an applicable ranges
of limits.

\subsubsection{Experimental Setup}

The transmitter discussed in ï¿½4.3 was analyzed in a carefully designed
experimental environment.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/area_transmitter/modelf_files/ExpID.jpg}

\caption{F Experiments}

\end{figure}

For this set of experiments, the setup was explicitly designed to
gather reliable functional data of the Model 'F' transmission broadcast.
This included the following test equipment:
\begin{itemize}
\item Hewlett-Packard (HP) 8640BOPT001 Signal Generator. Range (f): 10Hz
to 512MHz, Range (p): -75 to +20dBm,
\item HP4192AOPT001 Impedance Meter 5Hz to 13MHz,
\item HP8553A, HP8555A with 141T display Spectrum Analyzer
\end{itemize}
Special attention was given to the calibration of the devices which
was personally conducted by the author 14 months before the experiments
were conducted. Each of the components in the system--cables, adapters,
connectors, stop and feed-through terminations--were checked for
their accuracy where appropriate or for their network values in both
inductance and capacitance quantities as well as impedance and reactance
values. 

\subsubsection{COMSOL Multiphysics Modeling}

Simulation is an important consideration of the concepts comprising
this thesis. A relatively new tool, Multiphysics modeling, implies
that meaningful simulations of today\textquoteright s complex systems
require arbitrary couplings between different physics phenomena in
one and the same model. Such couplings in this thesis section denoted
'Wireless Power for Robot Orchestrated Colonies (WPROC) will attempt
to analyze such a complex system and demonstrate tools for analysis.
The coupled multiphysics models will be arbitrary couplings between:
\begin{itemize}
\item central transmitting complex (queen),
\item mobile receiving swarm quad/bipeds (drones),
\item control and orchestration of power distribution model.
\end{itemize}
Some more detailed questions relevant here are:
\begin{itemize}
\item What are the geometries of the system under study?
\item How can the problem be broken down into manageable pieces for grant-based
experiments, and into publishable results?
\end{itemize}
Referring back to Figure 2, in the discussion of orchestration ï¿½3.1,
the description of the system under consideration for multiphysics
modeling is a cavity-resonant conical transmitter/receiver with an
extensible conic cap.

The queen is coupled (as a whispering gallery with ellipsoidal transmission
pathways) to a collection of social autonomous robots, drones, who\textquoteright s
quadruped bodies form a conductive shape and surface area creating
a means of an inductive potential. They\textquoteright re body shape
can transform its length along the x-axis and the z-axis by mechanical
means of standing upright bipedally in an equidistant fashion. The
purpose of the morphology is to allow more directional receivership
at a cost of mobility speed. Some of the features are that this is
a high capacitance, high impedance system---to aid in powering devices
in the far-field where the edges of the eddy currents will be boosted
in range by the placement of signal relays---of two flavors, coupled
and uncoupled fields. Coupled uses a series of concentric circles
on the charge and uncoupled uses a contiguous spiral.

Model Requirements: An electrically charged conic section powered
by a single \emph{n} turn Archimedean spiral coil coupled to a linear
coil (filament) running its length along the z-axis. The spiral\textquoteright s
outer radius r$_{\text{s}}$, and inner radius r$_{\text{i}}$ are
arranged such that the radius of the filament r$_{\text{f}}$ with
length l$_{\text{f}}$, is related to the spiral as: r$_{\text{f}}$
<\textcompwordmark < r$_{\text{i}}$. At the apex of the filament
lies a conic section acting as a transmission antenna T$_{\text{a}}$.
The field is (smoothed / amplified / radiated) by an outer conic section
T$_{\text{b}}$. Consider the figure:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/primitiveModelState.jpg}

\caption{Primitive Model State}

\end{figure}

Here is expressed the queen transmitting apparatus. This model is
simply a mock-up, to get a sense of how the functional model should
appear resulting from the conceptual sketch exhibited in Figure 2.
A more concise model, including the capacitance hooks and more detailed
charge distribution is:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/compositeModelState.jpg}

\caption{Composite Model State}

\end{figure}

This is the current state of the model at this time. It is for the
continuation this thesis that it will be more worked out. However,
it is also necessary to mention that the model provides no insight
into its function without reference to an environment of some kind.
In this instance, it is simply an area surrounding so that the equations
can operate.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/modelEnvironment.jpg}

\caption{Simplified Model in an Environment}

\end{figure}

Figure 19 expresses the core as a function of its limit---at transponder
minimum placement where the relays would be placed. The next task
is to add the material and electrical characteristics.

\subsection{Controllers}

Here we discuss some of the ways the controllers for the system were
virtualized and understood under such terms.

\subsubsection{Visual Robotics and Virtual Controllers}

In the Summer of 2006, Microsoft introduced a software development
system called 'Robotics Studio', it offered a means of simulating
the strongly parallel operations indicative of robotic architectures.
Services could be manipulated and demonstrated on the computer's local
server while simulation was hosted through a game accelerator called
Ageia PhysX. While at the time limited to a few graphics cards, by
the Spring of 2007, with the introduction of Active X plugins to the
Ageia PhysX engine, the simulator was available to a more diverse
population of Intel chip machines save those able to run virtual machines
hosted within their operating system (OS). Coupled with the interface
development environment (IDE) of Visual Studio (VS), controllers could
be made completely virtual and highly modularized so that they could
coordinate with other controllers and interfaces including those present
in stimuli-response, audio-reactive, voice-command, and visual-stimulus
models.

A direct result of working with this software is a controller method
built in visual basic and XML manifest files not wholly unlike complex
software entities used in commercial enterprises. This points to an
interesting insight is a wide-scale commercialization of robotics
maybe starting to occur now and continue on a path of evolution over
the next decade. If this assumption is presented as true, then it
is a race to create a motif of classification of differing types of
robots categorized by their objectiveness in interfacing with humans--I
argue a substantial measure of the effectiveness of machines. The
future looks very clear that robots will form a niche in society;
it is for us to determine what kinds of robots will be filling what
niche by centralized manufacturing and custom-developed, common-usage
software typologies.

The notion of building virtual controllers is much more streamlined
than working with real ones; it is apparent that the field of virtualization
and simulation will be the preferred method of prototyping new types
of technology. It will be during the term of this thesis approaching
dissertation that this notion will be explored further. However, to
the present point in development here and for reference to these ideas,
consider the following figure:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/ControlWindow.jpg}

\caption{Simulation of Environment \& the Virtual Controller}

\end{figure}

Here is shown a sample robot--a Roomba in this case from iRobot,
Rod Brooks'\footnote{http://www.irobot.com} company--in an environment
similar to that of earth in that it has the same gravity. The light
conditions were programmed by myself and the objects are part of a
catalogue available to the developer. In this case, I programmed the
reaction of the robot to the objects in its environment, as a function
of the motors. In this way I could understand if I applied a force
to the motors propelling the robot, what kinds of shearing effects
were present due to the surface of the ground and gravity? The result
was a compensation mechanism that could measure the difference between
these two numbers (shown in the figure). What would be the next step
here would be to program an onboard camera with a visualization window
(a window that would show the display of the camera) to 'see' what
the robot sees. By performing these kinds of experiments, I can understand
what is necessary to prototype a robot for particular environments.
I can change the environment to simulate, say, the surface of Mars
and include the necessary conditions the components of the robot would
be subjected to.

Additionally, it is advantageous to work with programming 'blocks'
when coding robotic architectures; it is apparent from works from
Breazeal et. al. that the behavior required of a human-machine interaction
and the associated emotional-logical capacities cannot be simply programmed
in typical C++ manner. Despite objectification, a staggered tier of
complex software concepts is becoming necessary. Memory management
needs to be smarter and can self-adjust operations coming from heaps
to stacks, the emotive responses of the machine to human expressions
and tones needs to be represented in terms of entities. There are
numerous ways of accomplishing this that will be addressed as the
thesis progresses, however, it is a crucial affair to find an appropriate
IDE wherein to code the abstractions of what will be the outwardly
observed behavior of the robot. Granted, all the concerns I address
are supremely complex to say the least, but if I can start to think
about how a creature would compile facts about the real world, I cannot
help but to try to address the abstractions represented in the software
domain; as a domain-specific language that should be mapped functionally
managed by intelligent agents. This is the point wherein I will begin
this part of the problem.

\subsubsection{Agents and their Effectors}

Agents are a concept on the road to artificial consciousness. Coupled
with the notion of autonomy, an autonomous agent is a powerful concept
that can lead into many very interesting avenues of research. Stan
Franklin (1995, 2003) defines an autonomous agent as possessing functional
consciousness when it is capable of several of the functions of consciousness
as identified by Bernard Baars\textquoteright{} Global Workspace Theory
(1988, 1997). Effectors are the parts of agent programs that interact
with outside software components. Connections are made between the
operator within the agent and the operation it needs to be performing. 

\subsection{The Choice Complex}

This section will detail a set of proposed experiments--a consequence
of the Choice Methodology--to test said hypotheses. I will detail
here the extensions of the wireless power system outlined earlier
in this document and I will reference where appropriate to give the
reader a sense of how I plan to pursue the goals I have set out for
this work. 

The Featured Power Environment (FPE) is a design for a physical system
to empirically test the aspect of choice in the machine.\footnote{See ï¿½2.2 for referrals to The Choice Methodology.}
It is inspired by the idea of Grey Walter\textquoteright s ideal of
\textquotedblleft free will\textquotedblright{} and its suggestion
of the role of choice leading to emergent behaviors in the autonomous
machine\cite{key-18}. The experiment will consist of tests for consistency
of a wireless power apparatus denoted the Model \textquoteleft F\textquoteright .\footnote{See ï¿½5.1.1 regarding the Model 'F' experiments.}

I propose to set up and experiment to demarcate the details of the
functions of the A, B, and C and the corresponding L, V, and X modes.\footnote{Please refer to Figure 3.}
In order for this to be accomplished, there are two systems that need
to be constructed to test the theory, a hardware and software prototype.
The system I am authoring is quite unique and methodologically based,
that is, it is designed to follow exactly the principles and tenants
necessary for true artificial life. Additionally, I am deploying a
method of transmission that uses musical structures transmitted at
intra-audio frequencies via the computer\textquoteright s sound card
to understand the features of resonance and communication between
the stationary computer and the mobile robot. These structures will
not be delved into with any great detail at this point as they are
only postulates after the initial tests.

There are three modes of operation available: high, average, and sleep
denoted A, B, and C respectively. In order for this two-way system
to function---information one direction, power the second---there
are two distinct circuits involved to satisfy the configuration: one
residing in the transmitting array (queen) and the other in the receiving
array (drone).

\subsubsection{The Transmitting Array (Queen)}

The Tx circuit is the first half of a resonant system. It contains
a primary P and secondary S circuits shown in blue Figure 6. The windings
are placed in a right-handed manner where P = 2 and S = 40. Tied to
the tower are three differential power circuits that regulate the
stimulus to Tx. A switch is placed at the end of the voltage circuits
and before Tx so that the array is only energized once the stimulus
is applied. There are four positions on the switch---A, B, C, and
D. (High, mid, low, and null.) Control of the switch is dependent
upon the collection of frequencies sent in the transmission and modeled
in the software. When a switch position is engaged, the circuit between
Tx and Rx is closed by its resonance at the given frequency. Power
is then delivered at the chosen level. The polling time is 10 seconds,
this means the array will transmit power for a duration of 10 seconds
once a request is received then it closes (resets) the switch to the
null state. This feature is subject to change as the system is constructed.
Only when the switch resets to null will it listen for requests.

\subsubsection{The Receiving Array (Drone)}

The Rx circuit is the second half of the resonant system. It also
contains a primary P and secondary S circuits shown in black in Figure
6, but is wound symmetrically opposite. At its output is the received
power which, for the purposes of this experiment, is sent via wire
for signal processing in a stationary computer. After processing,
the data from the waveforms is sent for manipulation and handling
in the software structures. The software is the predominant force
in controlling the behavior of the hardware. It is envisioned that
the control paradigm will be the responsibility of the mobile machine,
or drone, to properly poll for energy and to communicate with the
central fixed-computing nexus or queen. It is my intention once the
software model is proven that the software can leave the fixed machine
and migrate to a mobile machine.

\subsubsection{The Software Model}

In order to properly engage the model, a framework and feedback relationship
is first established as a relationship between hardware elements.
A sensor is installed between the capacitor storage system and the
feed-through line in the Entropic Circuit. Please refer to Figure
4. It monitors the state of the energy stored in the capacitor and
receives information from the load sensor which monitors energy consumption
and sends periodic data samples when requested. The system strives
for a state of stability\cite{key-19}; dependent upon data received
from the load sensor and the decision it makes, the power monitor
sends a command to the controller that generates bits in one of three
variations X, V, or L which corresponds to C, B, and A respectively.
Computationally, X, V, L represent 2, 3, 4 in a base$_{\text{5}}$
number system designed as an extension, in this instance, to the binary
environment. 

\subsubsection{The Experiment}

I propose is to perform an experiment to test the notions I have set
forth in a 'The Choice Methodology: A New Foundation of Structured
Machine Life'. It is my intention to prove my theory by performing
an experiment to legitimize my artificial life claims.
\begin{itemize}
\item Construct the data handling structure, a layered controller, and server
distribution.
\item Construct a method and testing environment for Model \textquoteleft F\textquoteright .
\item Chart the operation frequency of the transmission system and test
software integrity by sending processed information generated by the
dynamic data structures.
\item Discern the breadth and clarity of signals transmitted and received.
\item Simulate the switching array and the Entropic Circuit.
\item Test the virtual components and publish the results.
\end{itemize}
I expect the duration of this experiment to be one-year.

\subsubsection{The Hardware Experiment}

I will begin by using a laboratory setup in the following manner:

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/TheHardwareExperiment.jpg}

\caption{Choice Experimental Setup}

\end{figure}

The Transmitting Programming Station will simulate the queen by deploying
software that uses the sound card as a signal generator coupled with
the system clock crystal as an oscillator\footnote{http://superpositioned.com/articles/2006/01/24/sound-card-based-signal-generators}
to insure frequency accuracy of a minimum resolution of 0.005. The
system clocks of most computers manufactured within the last few years
can hold this accuracy\footnote{http://www.securityspace.com/smysecure/catid.html?id=51664}.
Actual waves will be synthesized in the audio range by the sound card.
A minimum expectation of accuracy of cards made within the past three
years is 16-bits. The sweep range of the transmitter is 2$^{\text{9}}$A$_{\text{m}}$
or nine octaves.

For purposes of calibration, a frequency counter is used to measure
the accuracy of the signal generator. The counter is a device that
measures frequency of oscillation of an incoming signal compared to
a crystal oscillator as a reference. This is exactly opposite a signal
generator. To properly task the system, two computers should be used
that have comparable accuracies. To establish the measurement calibration,
a self-reference will be taken by connecting a wire from sound\_out
(speaker) to sound\_in (microphone) on the single computer, then to
sound\_in on the second computer to set a baseline of the difference
(error) compared to the reference. I do not make the claim that this
experiment will generate any absolute measurements, but relative in
when the drone sends information on a particular frequency band to
request power that it will be recognized by the queen.

The Signal Analysis Station will simulate the drone in software and
test the functioning of the coupled apparatus. It also will simulate
the components represented in the Entropic Circuit. The station will
measure the incoming signal to Rx and pipe it to the software application.

At the present time, I plan to separate Tx and Rx by a distance of
three meters.

During test, specific forms will be used to take observed data that
will later be transposed into a digital document pursuant to publication.
Digital pictures and movies will also be recorded.

\subsubsection{The Software Experiment}

The first step is to create a database. I postulate that information
storage and management is the most critical feature of a thinking
machine.

Pursuant to the theory, the database structure contains a structured
query language (SQL) corresponding to a set of tables with frequency,
power, parameters, decision, and foreign keys linked to all the notes
within octaves that can be generated within the range of the computer\textquoteright s
sound card. The range of tones available is 13, or between the start
of one octave and the next, taking A$_{\text{m}}$ as the lower limit
and A$_{\text{n}}$ as the upper limit. Coupled to the hardware system,
there are nine octaves available, the range represented by 2$^{\text{9}}$A$_{\text{m}}$.
The hardware will be allowed to transmit up to four tones simultaneously
to investigate the possibility of a method of information transport
in the resonance structure of the chords for communication in future
incarnations of machines. So that at the value\textquoteright s assignment
X, V, or L (representing A, B, and C in the choice complex), is in
breadth no greater than double the lower-limit frequency.

In choosing the database technology, cost and usage factors were considered.
I made the decision to use a relational structure under open-source
packages in SQL. Pursuant to this, I am using MS SQL Server Manager
2005, and EMS SQL Manager 2005 Lite in tandem with SQL Server Express
v9.0.2047. A deeper understanding of the structural aspects of the
database logic and the associated mathematics comes from Edgar F.
Codd\cite{key-20}. Applications that couple to the database will
either be C\#, Ruby, XML, or Java depending on design parameters.

The crux of the experiment is to understand why the structure of how
the data is queried by the robot is of critical importance to having
it understand the choices it has the ability to make contrasted with
the failure penalty of death.

\subsubsection{The Governing Equation}

The software architecture possesses the same transformation-logic
array of the hardware model. The software paradigm is a modular, domain-specific
programming language; it parses, sorts, scripts, compiles to objects,
transforms, and generates input and output channels. A domain-specific
language (DSL) is created specifically to solve problems in a particular
domain and, in the general case, is not designed to solve problems
outside of it. In contrast, a general-purpose language (GPL) is designed
to solve problems in many domains with an extensive toolbox that does
not necessarily focus on the specific case. Many DSLs do not compile
to byte-code or executable code like GPLs, but to various kinds of
objects. DSLs have exposed APIs that can be accessed from other programming
languages without breaking the flow of execution or calling a separate
process. Thus, they can be designed to operate as programming libraries. 

The domain in this specific case is a synthesized core governed by
a simple parametric equation which would yield complex behavior:

\begin{equation}
y=\mbox{a cos(t)+b sin(t)}
\end{equation}

on a limit between 0 and 4, whose solution generates objects, tables,
data structures, tools, and transformations. It additionally manifests
channels that allow generic software to compile against its libraries.
In this way, it seamlessly integrates with the generic robotics platform
and its onboard default language set.

The domain consists of the following members:
\begin{itemize}
\item data elements,
\item tables,
\item parameters,
\item an engine (virtual processor),
\item an assimilation mechanism---the absorption of data from external
data sources such as a remote server or computing nexus.
\end{itemize}
A further breakdown of how each of the members fits into the composite
schema can be seen in Figure 22. At this time the structure is completely
hypothetical and unique in this field.

\begin{figure}[H]
\includegraphics[scale=0.5,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/governingEquation.jpg}

\caption{Software Structured Choice and the Governing Equation (Concept)}

\end{figure}


\subsubsection{Some Anticipated Conclusions}

It is a goal to create a subjective model of artificial experience
in a natural environment by establishing an asymptotically-bounded
region in where to make a choice. Depending on its response to data
will establish a pattern of behavior (summation of choices). This
dynamic task, synthesized here but present in all living systems,
cognizant or instinctual, I argue will follow the same functional
pattern:
\begin{quote}
data \textrightarrow{} information \textrightarrow{} knowledge \textrightarrow{}
decision \textrightarrow{} action
\end{quote}
This flow process shows that data is converted into information, and
information is converted into knowledge once data has been organized
in a coherent and meaningful manner. The key, when a successful adaptation
occurs, is where the product \emph{knowledge} has high synthesis of
evaluation and organization and used purposefully enough so that the
entity survives to the next experience by making effective decisions.

How can this flow process be replicated in a synthetic form? The machine
requires a method to successfully manage data it receives from its
sensory devices; it requires a data management system (DMS).

The most common DMS today is SQL, a relational database system. Another
minor type of DMS is the transactional database system. The model
in most common use today is the relational model, which represents
all information in the form of multiple related tables each consisting
of rows and columns.

At the present time, I am constructing a relational SQL database coupled
to a transformation-based XML application structure (Figure 22) to
begin writing this artificial life system pursuant to the theme of
creating an artificial life form. I am confident I can establish a
solid empirical results about the phenomena of choice in synthetic
systems by conducting this work in the manner described.

\subsubsection{Experimentation Toward Understanding of the Choice Complex and Methodology}

There are really two experiments to consider here, the wireless power
technology and the associated frequencies of transmission and information
transfer, and choice in the machine. I have illustrated the first
in the previous section. Now I would like to outline a physical robot
wherein to test if choice can be studied empirically.

Consider a simple robot consisting of a hand, an arm and a microprocessor
'brain' with the following specifications:
\begin{itemize}
\item 32-bit ARM7 main microprocessor
\item 256 KB flash memory
\item 64 KB RAM
\item 8 bit Atmel AVR microcontroller @ 4 MHz
\item 4 KB flash memory
\item 512 Bytes RAM
\item 100 \texttimes{} 64 pixel LCD matrix display
\item Can be programmed using Windows or MacOS (NBC/NXC supports Linux as
well)
\item Users create a program with new software, powered by LabVIEW from
National Instruments
\item A single USB 2.0 port
\item Bluetooth (Class II) wireless connectivity, to transfer programs to
the NXT wirelessly or offer ways to control robots remotely (through
mobile phones and possibly by PDA's)
\item 4 input ports, 6-wire cable digital platform (One port includes a
IEC 61158 Fieldbus Type 4/EN 50 170 (P-NET) compliant expansion port
for future use)
\item 3 output ports, 6-wire cable digital platform
\item Digital Wire Interface, allowing for third-party development of external
devices 
\end{itemize}
Using a easily and visually programmed device allows for concentration
on the more complex tasks I would like to begin to orchestrate. A
proposed and simple task would be: Given a simple task dictated by
the 'environment', such as choosing between two different colored
balls sitting on stands and moving the 'favorite' to a bin. Listing
the input devices required:
\begin{itemize}
\item An ultrasonic sensor to measure the field of vision,
\item A light sensor to measure the color of the objects in the field of
vision,
\item A touch sensor to acknowledge whether or not the object has been grabbed.
\end{itemize}
Each sensor would need to be organized pertaining to its purpose and
purported task in this instance. {[}Remainder not available at time
of publication.{]}

\subsection{Some Final Thoughts Regarding the Subject Matter}

Considering the vast intertwining of the components listed in this
thesis, what kind of lasting impressions can be expected?
\begin{enumerate}
\item New and inventive software realizations,
\item New and inventive hardware realizations,
\item Extending commonality of unique ideas of research and commercial projects
perhaps changing the field,
\item Advancing the state of robotics, the understanding of humanity, and
life in a profound sense.
\end{enumerate}
A set of final thoughts and considerations that are more an extension
of the abstractions already discussed here. If a machine could be
made complex enough, would it respond to emergence? In other words,
would it possess some sense of artificial consciousness? A step in
that direction, is to study emotional states of the machine in regard
to it having the power to make choices over its interaction with an
environment. 

How would the machine react emotionally, as an extension of its logic,
in the Kismet sense of the transformation?\footnote{For a detailed discussion of Kismet, see Cynthia Breazeal, her dissertation
``Sociable Machines: Expressive Social Exchange Between Humans and
Robots'' about the relationship between logic and emotion. She argues
that they are connected entities and are intertwined in consciousness. } What kinds of pleasure responses are available to a machine? In living
creatures, pleasure is marked by the absence of threatening conditions,
in other words, the measurement of one in context of another. So,
how would a balance of giving / taking away affect the development
and sociability of an artificial life form? If it could be made to
understand degrees of entropy by hinting at the meaning of these states,
would the machine choose to fight to preserve itself and its consciousness
and the assembly of states of pleasure it came to associate with it?

I suppose the burning question is: Can life be understood by placing
it in tension with its polar opposite? Or by degrees of entropy? Does
the very existence of entropy preclude a life with richer experiences?

Some final words about choice and the directive it takes in this thesis.
Life is determined by action-reaction; that is there is only one real
Truth in the universe--causality. Some proffer the observation that
everything begins with choice, this is a fallacy. Choice is an illusion
between those with power and those without. Does this imply that the
future roboticist is irrevocably attached to his creations or does
this imply a hierarchy of machines is necessary for a division of
power or authority in the same manner as human societies for them
to be in some sense alive? At this point, I will not pretend to know,
but it is something I would like to find out.

\section{Conclusions}

I believe the most immediate benefit to humanity is the application
of wireless power to cybernetic implants, the waves would need to
be studied at length to check for any deleterious effect on human
tissue but I think its a worthy try. Power for pacemakers and the
like could be gleaned from a pack worn on at the surface of the skin--perhaps
strapped to the arm--instead of having to be subjected to operations
to replace worn out battery cell-packs. Or if the implant is too small
to be powered any other way other that wirelessly. The circuitry could
be made incredibly small faced with the requisite that the transmission
pad be sufficiently large, which preliminary equations seem to be
saying the system obeys this principle.

What I have discovered during my time working on this thesis:
\begin{itemize}
\item I have discovered that the field of AI/AL is a place of diverse opinion
and less of a results-oriented field than more empirical fields such
as physics and engineering.
\item I find the work fascinating and novel. This is the first time in the
history of civilization we have come this close to sentient machines--for
better or worse.
\item I enjoy the work and learning new things. As such, it has kept my
spirit high and my faith in things more or less constant.
\item I think it is important to keep in mind that it is the spirit of discovery
and to provide some important insights into what it means to be alive
and human.
\item And for that, I am thankful.
\end{itemize}

\section{Appendix: Replicas--The Plan}

\subsection{Plan Summary}

The project\textquoteright s overall plan and development strategy
has been prepared for the period beginning 2007 until 2010. This plan
has been subjected to the scrutiny of professional persons and agreed
that as a plan, is due to remind the reader that it is only an acknowledgment
of the honesty of doing the work required and a benchmark of current
expertise. The goal is to place myself at the leading edge of artificial
adaptive cognitive structures pursuant to full-blown artificial life
forms manifest in a variety of physical manifestations. This goal
is purveyed upon the concept of self-replicating machines; however,
for these purposes, the scope of such is limited to information self-replication
and organization rather than physical implementation. The thought
is to prove a template example of how a system (algorithm) would adapt
to its environment and self-organize the data received from it.

The idea revolves around the problem of artificial life, which historically
can be broken down into four main components:
\begin{enumerate}
\item The Problem of Energy (subsistence),
\item The Problem of Communication {[}inner: connections (wires); outer
cooperation (society){]},
\item The Problem of Control (manipulation of the environment),
\item The Problem of Raw Materials (reproduction).
\end{enumerate}
In this sphere, the difference between internal processes and external
schema are irrelevant as each are strictly dependent on the other.
I will define what I mean by this statement shortly.

\subsection{Concept}

In addressing the problems surrounding artificial life, the predominant
question reflects back to the eternal question: What is life? A keyword
search of \textquotedblleft life\textquotedblright{} on the Internet
will elicit the general characteristics: 
\begin{enumerate}
\item Homeostasis: Regulation of its internal environment to maintain a
constant state.
\item Organization: Being composed one of or more \textquoteleft basic\textquoteright{}
units such as cells.
\item Metabolism: Consumption of energy by converting non-living matter
into material for the \textquoteleft basic\textquoteright{} units
and decomposing matter.
\item Growth: Maintenance of a higher rate of synthesis rather than catalysis
in order to increase the preponderance of its parts.
\item Response to stimuli: A autonomous or calculated event causally related
to an environmental state.
\item Adaptation: Altering its fundamental processes, including behavior,
in response to environmental stimuli.
\item Reproduction: The introduction of new organisms based upon itself.
\end{enumerate}
These being rather general and more of a consensus of opinion rather
than based on empirical evidence, a more narrow definition founded
in statistical physics can be found based on the concepts of order,
disorder, and entropy\cite{key-22}. The following constitute \emph{Criteria
One}:
\begin{enumerate}
\item Order based on order: The tendency of an organism to strive for order
based on the negative consequence of disorder.
\item Creating order based on disorder: Manipulation by the organism to
achieve maximum order by avoiding a decay into equilibrium, or purposefully
trying to keep itself away from a permanent state by feeding on negative
entropy.
\item Creating order based by extracting order from the environment: The
consumption of energy or information as the fuel for the engine of
the organism\textquoteright s unique state which remains non-permanent.
\end{enumerate}
For the purposes of this definition of concept particular to this
research, I can now address: What is artificial life? Since the form
is artificial by nature, that is, reflectively speaking, intentionally
created to serve the purpose it was created for, I will argue it is
more privy to a statistical definition delineated by Schrï¿½dinger than
by general characteristics outlined previously. Accepting this as
a suitable foundation lacking any further competing hypotheses, what
attributes should such a form possess? I offer it should:
\begin{enumerate}
\item Strive for order based on disorder.
\item Strive for a successive series of states keeping it distant from equilibrium.
\item Create its own sense of order by extracting information from its environment.
\item Replicate its internal mechanisms to facilitate adaptation.
\item Grow by increasing its composite store of information, enhancing its
decision-making faculties.
\item At present: internal replication manifest in a software domain to
understand its potential in the model.
\end{enumerate}
In order to generate empirical evidence of the hypothesis I have offered,
I insist the first glimpse of artificial life needs to be \textquoteleft manifest\textquoteright{}
as a result of self-construction, modification, adaptation, and replication.
I will not offer any previous demarcation of how such a process has
or should be developed or founded upon any \textquotedblleft thought
experiments\textquotedblright \cite{key-23} or any other semblance
of such; I will not offer any positioning of my thesis jockeyed as
an opposing viewpoint such as anti-Turning, von Neumann architectures
or machines, universality or relativism, or entertain by validating
any method or charge, as such discourses have not amounted to any
significant development\cite{key-15} and alternatively, have resulted
in failure in the general cases\cite{key-24}. The only pre-foundation
reference will be in the language of reconfigurable computing using
data counters to generate the addresses of memory blocks that can
be clearly illustrated by Uhoo. This may or may not include systolic
arrays as a means to allow for parallelism; however, I foresee my
own solution in this sphere using the tools that are available to
me.

\subsection{The First Consideration}

Following the path resulting from embracing Criteria One, all work
under this tutelage has four features which obey their assignment.
These four features are:
\begin{enumerate}
\item Self-Construction,
\item Modification,
\item Adaptation, and,
\item Self-Replication.
\end{enumerate}
In considering these features, I foresee the best strategy in manifesting
these in union and not independently as these are explicitly dependent
upon each other for mutual benefit. Numbers one and four are two facets
of the same phenomena, form one-half of the total problem, but have
been split for clarity. The same can be said of numbers two and three
as adaptation, the second-half of the problem, as the engine of self-modification.

Considering the form in context with its environment and moving in
linear time, there are three dynamic features inherent in the life
form:
\begin{enumerate}
\item Creation,
\item Causality, and,
\item Change.
\end{enumerate}
It must start somewhere, be subject to not only its environment but
be responsible for its decision-making, and be able to account for
the consequences of its decisions for maximum benefit.

\subsubsection{Feature Breakdown}

In order to understand, generate empirical evidence of the thesis
at hand, and to facilitate the Replica, a model should be designed
and tested to meet Criteria One\textquoteright s standards. Specifically,
the model should address self-construction and modification based
on changing conditions.

A self-replicating machine would need to have the capacity to gather
energy and raw materials, process the raw materials into finished
components, and then assemble them into a copy of itself. It is unlikely
that this would all be contained within a single monolithic structure,
but would rather be a group of cooperating machines or an automated
factory that is capable of manufacturing all of the machines that
make it up. The factory could produce mining robots to collect raw
materials, construction robots to put new machines together, and repair
robots to maintain itself against wear and tear, all without human
intervention or direction. The advantage of such a system lies in
its ability to expand its own capacity rapidly and without additional
human effort; in essence, the initial investment required to construct
the first self-replicating device would have an infinitely large payoff
with no additional labor cost. Such a machine violates no physical
laws, and we already possess the basic technologies necessary for
some of the more detailed proposals and designs. If proof were needed
that self-replicating machines are possible the simple fact that all
living organisms are self replicating by definition should go some
way towards providing that proof, although most living organisms are
still many times more complex than even the most advanced man-made
device.

\subsubsection{Computational Considerations and Engineering Environments}

My position in classifying the computational structure of the first
iteration, \emph{Uhoo}, is that it is an algorithm. That is, it contains
the necessary variables and instructions (procedure) to describe its
state and operational domain strictly based upon well-defined parameters.
It possesses a finite set of well-defined instructions, based on the
work of three agents, accomplishing a given task terminating their
work once the sequence is complete---the form in constructed and
the data spaces defined and bounded.

As an algorithm based generally on the definitions surrounding Turning
machines and lambda calculus, I will not dwell on purely intellectual
queries and permutations; instead, migrate the notion to an exemplary
development environment to further engineer it.

In order to make the model as general and portable to as many types
of computing architecture in a common-use language, I will model the
algorithm in Scilab, deploy in SQL with C\#.XSD as the primary data
handler and an application delivery layer, XML as a higher level organizational
tool, XSL to address any reflective transitions, .NET and its open
source cousin, Mono, as a framework class library to testing machines
and \textquotedblleft lite\textquotedblright{} versions for targeted
inexpensive mobile devices such as Lego NXT and RoboSapienv3 (available
to be controlled form other mobile devices such as mobile phones with
Bluetooth), and a standard .exe format in both local WinForm and WebApp
environments for distribution across local and networked computers
and testing robots.

Further, I foresee the migration from Scilab-generated code, generally
regarded as C, of the original data class to physically testing and
generating empirical evidence of the concept with a common use runtime
such as SQL coupled closely with C\#. The reason for the choice of
C\# is because of the deployment within Robotics Studio and its built-in
toolbox with physical robot units such as many off-the-shelf packages.

\subsubsection{Historical Inspiration of the Model for Artificial Life}

I tend to believe there is much to learn from history and that it
is an important scientific principle to look to see what has already
been done instead of trying to reinvent. Time is better spent in the
laboratory performing experiments further emboldening the theories.

In trying to define the question: What is artificial life?, I found
myself on a multifoil containing at a minimum of six different means
to go starting to answer the question. They were:
\begin{enumerate}
\item Past works and architectures,\footnote{Inspired by Archimedes, Ancient Greek mathematics, and the Antikythera
Mechanism.}
\item Nouveau artificial life techniques and procedures\cite{key-25},
\item Past iterations of physical machines,\footnote{The Clockwork Monk by Elizabeth King.}
\item Appearances of well-defined machines in science fiction,\footnote{See the section entitled 'Conceptual Aids'.}
\item Philosophy\cite{key-26},
\item Thought experiments.
\end{enumerate}
These have extended from recursive functions, the lambda calculus,
the Turing and Post-Turing machine, and the \textquotedblleft reckonable
in the system S$_{\text{1}}$\textquotedblright \cite{key-27}. An
entire paper could be written on the implications of the philosophy
of mind resulting from an analysis of the works contained within the
Church-Turing thesis; however, it has been and will continue to be
my intention to get away from philosophy and focus on the problems
of engineering. The historical inspirations, for positive or negative,
have effected the outcome of this thesis and my decisions to take
such an attitude.

\subsection{The Second Consideration}

The fundamental definition: life is matter with meaning, will be used
as the definitive answer to the question posed earlier in this document.
There is mention of an autonomous \textquotedblleft epistemic cut\textquotedblright{}
in philosophy that will need exploration to further fill this out.
In immediate redress, however, \textquotedblleft Unlike physical theory,
great discoveries in the evolution of natural and artificial life
are closely related to understanding how the description-construction
process can be most efficiently \emph{implemented}.\textquotedblright{}
{[}Pattee 28{]}. Discovery and implementation of a genotype-phenotype
transformation is the crux of the problem.

Of course, implementation-independent self-organization may play essential
roles in the origin of life and in limiting the possibilities for
natural selection. The significance of these roles needs to be determined\cite{key-28}. 

\subsection{The Third Consideration}

The artificial physical world complete with its own set of laws, descriptions,
and sequences. In order for the system to maintain and evolve, the
organism must efficiently implement the artificial physical descriptions
as constructions.

\subsection{The Fourth Consideration}

A crucial feature resides in design considerations, how the features
are constructed, their methodology, and most importantly, how they
are implemented with emphasis upon efficiency.

Considering the choice of the object-oriented C\# language, it is
wise at this point to demarcate a strategy of what designs are available
and the best ones based on empirical tests.

Today, most designers point to GoF, or Gang of Four, referring to
the seminal book \emph{Design Patterns}, published in 1995 but still
serving as the quintessential reference on the subject. It is a focal
point to look at the problem as one of pattern and not necessarily
of implementation as patterns can be rendered in a high-level language
as long as one understands the criteria involved. Another key point
is to realize that reusability of existing code also increases efficiency,
i.e., once a task is learned and the code written, the entirety or
pieces of the experience can be repeated where necessary. As such,
there are six major considerations of choosing the proper pattern:
\begin{enumerate}
\item Consider how design patterns solve problems.
\item Scan Intent sections. Consider each pattern\textquoteright s intent
to find the one relevant to the problem at hand.
\item Study how patterns interrelate.
\item Study patterns of like purpose.
\item Examine a cause of redesign.
\item Consider what should be variable in the design.
\end{enumerate}
Pursuant to this, the following table condenses the above six into
a single format.

\begin{figure}[H]
\includegraphics[scale=0.4,bb = 0 0 200 100, draft, type=eps]{../../research/publications/UoR thesis/z-archives/master/figures/tableOne.jpg}

\caption{A Table of Design Patterns}

\end{figure}

Now it should be determined what patterns to pick and how to use them.
There is a eight-point process.
\begin{enumerate}
\item Read the pattern once through for an overview of what is available
by using it, the costs, benefits, and consequences to the remainders.
\item Study the Structure, Participants, and Collaborations to understand
the classes and object and how they relate to one another.
\item Look at available sample code to see a concrete example and test its
effectiveness in design and implementation.
\item Choose names for pattern participants that are meaningful in the application
context, stay away from naming conventions that are too abstract but
hint to their function(s).
\item Define the classes, declare their interfaces, establish their inheritance
relationship, and define the instance variables that represent data
and object references. Notice now they will effect the pattern.
\item Define application-specific names for operations in the pattern and
be consistent throughout.
\item Implement the operations to carry out the responsibilities and collaborations
in the pattern.
\item Do not apply the pattern indiscriminately. Understand the nature of
the problem and what is absolutely necessary without code \textquotedblleft bloating\textquotedblright .
\end{enumerate}
Having listed the essentials from the book, it is now time to administer
the concepts to the goals set forth in this orchestrated plan.

\subsubsection{Specific Considerations Set Forth}

One feature that the program, in its current iteration Uhoo, has the
ability to write its own code. Generally speaking, it possesses and
implements reflective programming. This will be better illustrated
during the term of this thesis.

\subsection{The Machine}

As it is the goal to produce a viable and pervasive machine, how have
the previous considerations contributed to the form of the Replica?
What have been my successes, my failures, my rewards, my costs, my
consequences and how has my first task of reproduction fared? Although
this thesis will only try to answer the questions about featured power
and choice, how do these ideas and the generated technologies aid
in larger frameworks?

I don't want this work to be considered in a vacuum; although I will
only deal with two specific technology types, I will from time to
time delve into the larger applications and demonstrate some notions
where possible. However, at the time of this draft, I include only
that which I believe will be relevant herein. Thank you for your consideration
and careful attention.

\begin{thebibliography}{10}
\bibitem[2]{key-2} Brooks, Rodney. \textquotedbl The Relationship
Between Matter and Life\textquotedbl , Nature. v409, n6818, pp. 409-411.
2001.

\bibitem[3]{key-3}Holland, Owen. \textquotedbl Exploration and High
Adventure: The Legacy of Grey Walter\textquotedbl . The Royal Society,
20 August 2003.

\bibitem[8]{key-8}Walter, Grey, W. The Living Brain. New York: W.W.
Norton \& Company. 1953a.

\bibitem[9]{key-9}Maslow, Abraham, H. Toward a Psychology of Being,
3rd Edition. New York: Wiley. 1998.

\bibitem[10]{key-10}Bateson, Melissa, Susan D. Healy, and T. Andrew
Hurly. \textquotedbl Irrational Choices in Hummingbird Foraging Behavior\textquotedbl ,
Animal Behavior, 63, 587-596, 2002.

\bibitem[11]{key-11}Holland, Owen \& David McFarland. Artificial
Ethology. Oxford: Oxford University Press. 2001.

\bibitem[12]{key-12}Ashby, Ross, W. An Introduction to Cybernetics.
London: Chapman \& Hall, Ltd. 1957.

\bibitem[13]{key-13}Melear, C. \textquotedbl Low-Power Techniques
for Modular Processors. WESCON/94. Idea/Microelectronics. 27-29 Sept
1994.

\bibitem[14]{key-14}Van Deursen, A. \textquotedbl Domain-Specific
Languages verses Object-Oriented Frameworks\textquotedbl , SmallTalk
and Java in Industry and Academia, STJA'97, pp. 35-39.

\bibitem[15]{key-15}Grand, Steve ``Communications with Steve Grand''
August 2006 to February 2007.

\bibitem[16]{key-16}Andre Kurs; Aristeidis Karalis, Robert Moffatt,
J.D. Joannopoulos, Peter Fisher, Marin Solja\v{c}i\'{c}. Wireless
power transfer via strongly coupled magnetic resonances\textquotedbl .
Science, Vol. 317. no. 5834, pp. 83 - 86, July 2007.

\bibitem[17]{key-17}Asimov, Issac. ``The Inevitable Conflict''
I, Robot. 1950.

\bibitem[18]{key-18}Walter, Grey, W. The Living Brain. New York:
W.W. Norton \& Company. 1953a, p.290.

\bibitem[19]{key-19}Ashby, Ross W. ``An Introduction to Cybernetics''.
London: Chapman \& Hall, Ltd. 1957, Chapter 3.

\bibitem[20]{key-20}Codd, E.F. ``A Relational Model of Data for
Large Shared Data Banks''. Communications of the ACM 13 (6): 377-387,
1970.

\bibitem[21]{key-21}Stanghellini, Giovanni. \textquotedblleft Autism:
Disembodied Existence\textquotedblright . Philosophy, Psychiatry,
\& Psychology, Volume 11, Number 3. The Johns Hopkins University Press.
September 2004, pp. 259-268.

\bibitem[22]{key-22}Schrï¿½dinger, Erwin. What is Life? The Physical
Aspect of the Living Cell. \textquotedblleft Lectures: Dublin Institute
for Advanced Studies\textquotedblright . Dublin: Trinity College.
February 1943. pp.69-74.

\bibitem[23]{key-23}Von Neumann, John, Arthur W. Burks (ed). The
Theory of Self-Reproducing Automata. Urbana: University of Illinois
Press. 1966.

\bibitem[24]{key-24}Brooks, Rodney. \textquotedblleft Rodney Brooks
Forecasts the Future\textquotedblright . The New Scientist, Number
2578, 60, November 2006.

\bibitem[25]{key-25}Grand, Steve. ``Growing up with Lucy''. London:
Weidenfeld \& Nicolson. 2004.

\bibitem[26]{key-26}Baudrillard, Jean. ``Simulacra and Simulation''.
University of Michigan Press. 1981.

\bibitem[27]{key-27}Kleene, Stephen. (cf Kleene 1952, p320.)

\bibitem[28]{key-28}Patee, H.H. ``Artificial Life Needs a Real Epistomology''.
1995.

\end{thebibliography}

\end{document}
